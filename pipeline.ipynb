{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json,re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from preparando_datos import sum_into_column,split_and_sum,get_min_max,compute_average\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#TODO polars\n",
    "\n",
    "\n",
    "\n",
    "df_train=pd.read_csv('dataset/origen.csv')\n",
    "genre_types = df_train['genres_x'].unique().tolist()\n",
    "\n",
    "genre_types = [genre.split(\",\") if type(genre)==str else ['Missing'] for genre in genre_types]\n",
    "genre_types = [item for sublist in genre_types for item in sublist]\n",
    "genre_types = list(set(genre_types))\n",
    "\n",
    "\n",
    "\n",
    "status_types = df_train['status'].unique().tolist()\n",
    "status_types.remove(np.nan)\n",
    "status_types.append('Missing')\n",
    "status_types.append('Canceled')\n",
    "\"\"\" \n",
    "for i, status in enumerate(status_types):\n",
    "    status_types[i] = f\"status_{status}\" \"\"\"\n",
    "#take a 10% sample out of train\n",
    "df_test =  df_train.sample(frac=0.1, random_state=43)\n",
    "#drop the sample from train\n",
    "df_train.drop(df_test.index, inplace=True)\n",
    "\n",
    "X_test = df_test.drop([\"averageRating\",'Unnamed: 0'], axis=1)\n",
    "X = df_train.drop([\"averageRating\",'Unnamed: 0'], axis=1)\n",
    "y = df_train[\"averageRating\"]\n",
    "y_test = df_test['averageRating']\n",
    "\n",
    "del df_test,df_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(eval(X['production_companies'].iloc[15])[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['runtimeMinutes'].replace(0, np.nan, inplace=True)\n",
    "X['budget'].replace(0, np.nan, inplace=True)\n",
    "X['revenue'].replace(0, np.nan, inplace=True)\n",
    "X['titleType'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan \"[{'iso_3166_1': 'IT', 'name': 'Italy'}]\" '[]' ...\n",
      " \"[{'iso_3166_1': 'FI', 'name': 'Finland'}, {'iso_3166_1': 'EE', 'name': 'Estonia'}, {'iso_3166_1': 'KE', 'name': 'Kenya'}]\"\n",
      " \"[{'iso_3166_1': 'IN', 'name': 'India'}, {'iso_3166_1': 'SE', 'name': 'Sweden'}, {'iso_3166_1': 'RS', 'name': 'Serbia'}, {'iso_3166_1': 'GR', 'name': 'Greece'}]\"\n",
      " \"[{'iso_3166_1': 'BE', 'name': 'Belgium'}, {'iso_3166_1': 'FR', 'name': 'France'}, {'iso_3166_1': 'PT', 'name': 'Portugal'}]\"]\n"
     ]
    }
   ],
   "source": [
    "print(X.production_countries.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype == 'O' and X[c].isnull().any()]\n",
    "\n",
    "categorical_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype == 'O' and X[c].notnull().all()]\n",
    "\n",
    "\n",
    "\n",
    "numerical_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].isnull().any()]\n",
    "numerical_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].notnull().all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformFromDict(BaseEstimator, TransformerMixin):\n",
    "    #Voy a intentar explicar esto lo mejor que puedas\n",
    "    def __init__(self, variables:list):\n",
    "        #\n",
    "        if type(variables) == str:\n",
    "            variables = [variables]     \n",
    "        self.variables = variables\n",
    "\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        def get_str(x):\n",
    "            #x is missing\n",
    "            if x is np.nan or x is None or x == 'Missing' or x == 'nan' or x == '[]' or x == '':\n",
    "                return ''\n",
    "            x = eval(x)\n",
    "            names = []\n",
    "            if type(x)== list:\n",
    "                for item in x:\n",
    "                    if type(item)==dict:\n",
    "                        name = item.get('name', '')\n",
    "                    else:\n",
    "                        name = ''\n",
    "                    names.append(name)\n",
    "            else:\n",
    "                names.append('')\n",
    "            return ','.join(names)\n",
    "        for group in self.variables:\n",
    "            X[group] = X[group].apply(get_str)\n",
    "        return X\n",
    "lista = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import AddMissingIndicator, CategoricalImputer, MeanMedianImputer\n",
    "from feature_engine.encoding import OneHotEncoder,RareLabelEncoder\n",
    "from feature_engine.selection import  DropFeatures\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def interpolate_numericals(df, group, category, method='linear'):\n",
    "    # Fill in missing values using interpolation\n",
    "    df[category].replace(0, np.nan, inplace=True)\n",
    "    df[category].interpolate(method=method, inplace=True)\n",
    "    \n",
    "    # Store the fitted values in a dictionary\n",
    "    if group not in interpolate_numericals.fitted_values:\n",
    "        interpolate_numericals.fitted_values[group] = {}\n",
    "    interpolate_numericals.fitted_values[group][category] = df[category].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Initialize the fitted values dictionary\n",
    "interpolate_numericals.fitted_values = {}\n",
    "for to_remove in ['budget','revenue']:\n",
    "    try:\n",
    "        numerical_columns_with_nan.remove(to_remove)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "def check(x):\n",
    "    print(f\"Number of missing values in titleType before categorical imputer: {x['titleType'].isna().sum()}\")\n",
    "    return x\n",
    "\n",
    "pipeline_preprocessing = Pipeline([\n",
    "    ('turnToNan', FunctionTransformer(lambda x: x.assign(runtimeMinutes=x['runtimeMinutes'].replace(0, np.nan),\n",
    "                                                          budget=x['budget'].replace(0, np.nan),\n",
    "                                                          revenue=x['revenue'].replace(0, np.nan)))),\n",
    "    ('numericalMissingIndicator', AddMissingIndicator(variables=numerical_columns_with_nan)),\n",
    "    ('categoricalMissingIndicator', AddMissingIndicator(variables=categorical_columns_with_nan)),\n",
    "    ('runtimeTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'runtimeMinutes'))),\n",
    "    ('budgetTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'budget'))),\n",
    "    ('revenueTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'revenue'))),\n",
    "    ('endYearsTransform', FunctionTransformer(lambda X: X.assign(endYear=X.apply(lambda x: x['startYear'] if x['endYear'] == 0 else x['endYear'], axis=1)), validate=False)),\n",
    "    ('categoricalImputer', CategoricalImputer(variables=categorical_columns_with_nan,fill_value='Missing')), \n",
    "    ('meanMedianImputer', MeanMedianImputer(imputation_method='median', variables=numerical_columns_with_nan)),\n",
    "    ('getSTRsFromDicts', TransformFromDict(variables=['production_companies','production_countries'])),\n",
    "    #('tvCategories',RareLabelEncoder(tol=0.01,n_categories=6, variables=['titleType'],replace_with='Other_TV')),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetExpDict(BaseEstimator, TransformerMixin):\n",
    "    #Voy a intentar explicar esto lo mejor que puedas\n",
    "    def __init__(self, group:list, categories:list,targets:list=[''],simple_only:list = []):\n",
    "        #\n",
    "        if type(group) == str:\n",
    "            group = [group]\n",
    "        if type(categories) == str:\n",
    "            categories = [categories]\n",
    "        if type(targets) == str:\n",
    "            targets = [targets]\n",
    "        group.extend(simple_only)\n",
    "        self.group = group\n",
    "        self.categories = categories\n",
    "        self.simple_only = simple_only\n",
    "        self.targets = targets\n",
    "\n",
    "    def process_group_category_target(self,group, category, target, X):\n",
    "        #print('Processing group:',group, category, target)\n",
    "        categorias = X[category].unique().tolist()\n",
    "        categorias = [x.split(',') if type(x) == str else [] for x in categorias]\n",
    "        categorias = [item for sublist in categorias for item in sublist]\n",
    "        categorias = list(set(categorias))\n",
    "        grupo = X.groupby(group).apply(lambda x: [(g, v) for g, v in zip(x[category], x[target] if target!= 'exp' else [1]*len(x))]).to_dict()\n",
    "        if '0' in grupo:\n",
    "            del grupo['0']\n",
    "        return (group, grupo, categorias, target)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(self.group, self.categories, self.targets)\n",
    "        print('creating parallel fitting job')\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.process_group_category_target)(group, category, target, X) for group in self.group for category in self.categories for target in self.targets)\n",
    "        grupos = [result for result in results]\n",
    "        print('done')\n",
    "        self.diccionarios = Parallel(n_jobs=-1)(delayed(self._fit_group)(group, grupo, categorias,target) for group, grupo, categorias,target in grupos)\n",
    "        print('done')\n",
    "        return self\n",
    "    \n",
    "    def _fit_group(self, group, grupo, categorias, target):\n",
    "        # Create a dictionary with directors as keys and their shows as values\n",
    "        \n",
    "        dict_limpio = {}\n",
    "        for sub_grupo, shows in grupo.items():\n",
    "            for dir in sub_grupo.split(','):\n",
    "                dict_limpio[dir] = shows\n",
    "\n",
    "        # Initialize a dictionary to count categories\n",
    "        cat_counts = {}\n",
    "        for sub_grupo in dict_limpio.keys():\n",
    "            cat_counts[sub_grupo] = {}\n",
    "            for cat in categorias:\n",
    "                cat_counts[sub_grupo][cat] = [0, 0]\n",
    "\n",
    "        # Update the count for each category\n",
    "        for sub_grupo, values in dict_limpio.items():\n",
    "            for v in values:\n",
    "                cat = v[0]\n",
    "                count = v[1]\n",
    "                if cat in cat_counts[sub_grupo]:\n",
    "                    cat_counts[sub_grupo][cat][0] += count\n",
    "                    cat_counts[sub_grupo][cat][1] += 1\n",
    "\n",
    "        # Compute the average for each category and store it in authors_xp\n",
    "        authors_xp = {}\n",
    "        for sub_grupo, cat_dict in cat_counts.items():\n",
    "            authors_xp[sub_grupo] = {}\n",
    "            for cat, counts in cat_dict.items():\n",
    "                authors_xp[sub_grupo][cat] = compute_average(counts)\n",
    "        \n",
    "        return group, authors_xp, categorias, target\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Define a helper function for parallel processing\n",
    "        def process_group(group, diccionario, categorias, target):\n",
    "            new_columns = {}\n",
    "            if group not in self.simple_only:\n",
    "                new_columns.update({\n",
    "                    f'{group}_{target}_{category}': X[group].apply(sum_into_column, args=(diccionario, category,))\n",
    "                    for category in categorias\n",
    "                })\n",
    "            new_columns.update({\n",
    "                f'{group}_min': X[group].apply(get_min_max, args=(diccionario, 0, categorias,)),\n",
    "                f'{group}_max': X[group].apply(get_min_max, args=(diccionario, 1, categorias,))\n",
    "            })\n",
    "            return new_columns\n",
    "\n",
    "        # Run the helper function in parallel\n",
    "        results = Parallel(n_jobs=-1)(delayed(process_group)(group, diccionario, categorias, target) for group, diccionario, categorias, target in self.diccionarios)\n",
    "\n",
    "        # Combine the results\n",
    "        new_columns = {k: v for result in results for k, v in result.items()}\n",
    "\n",
    "        X = pd.concat([X, pd.DataFrame(new_columns)], axis=1)\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline_exp = Pipeline([\n",
    "    ('set_exp_dict_genres', GetExpDict(group=['directors',\"writers\"], categories=['genres_x','titleType'],simple_only=['production_companies','production_countries'],targets=['numVotes','exp','runtimeMinutes'])),\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okay(x):\n",
    "    print(\"Okay\")\n",
    "    return x\n",
    "def binarize_genres(X):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    print('0')\n",
    "    binarized_genres = mlb.fit_transform(X['genres_x'].str.split(','))\n",
    "    df_binarized_genres = pd.DataFrame(binarized_genres, columns=mlb.classes_)\n",
    "    \n",
    "    print('1')\n",
    "    for column in genre_types:\n",
    "        if column not in df_binarized_genres.columns:\n",
    "            df_binarized_genres[column] = 0\n",
    "    print('2')\n",
    "    df_binarized_genres = pd.concat([X, df_binarized_genres], axis=1)\n",
    "    print('3')\n",
    "    return df_binarized_genres\n",
    "\n",
    "#TODO: Comparar a ver si es mejor ni usar order, season y episodeNumber\n",
    "\n",
    "pipeline = Pipeline([('preprocessing',pipeline_preprocessing),\n",
    "                     ('exp',pipeline_exp),\n",
    "    ('okaycheck', FunctionTransformer(okay)),\n",
    "    ('okaycheck01', FunctionTransformer(okay)),\n",
    "    ('binarizeGenres', FunctionTransformer(binarize_genres)),\n",
    "    ('okaycheck0', FunctionTransformer(okay)),\n",
    "    ('removeEmptyRows', FunctionTransformer(lambda x: x.dropna(subset=['directors']))),\n",
    "    ('okaycheck1', FunctionTransformer(okay)),\n",
    "    \n",
    "    ('oneHotEncoder', OneHotEncoder(variables=['titleType',\"status\"])),\n",
    "    ('okaycheck2', FunctionTransformer(okay)),\n",
    "    ('removeCategorical',FunctionTransformer(lambda x: x.drop(x.select_dtypes(include=['object']).columns, axis=1))), \n",
    "    ('okaycheck3', FunctionTransformer(okay)),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['directors', 'writers', 'production_companies', 'production_countries'] ['genres_x', 'titleType'] ['numVotes', 'exp', 'runtimeMinutes']\n",
      "creating parallel fitting job\n",
      "done\n",
      "done\n",
      "Okay\n",
      "Okay\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Okay\n",
      "Okay\n",
      "Okay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC660ADBC0&gt;)),\n",
       "                                 (&#x27;numericalMissingIndicator&#x27;,\n",
       "                                  AddMissingIndicator(variables=[&#x27;runtimeMinutes&#x27;,\n",
       "                                                                 &#x27;seasonNumber&#x27;,\n",
       "                                                                 &#x27;episodeNumber&#x27;,\n",
       "                                                                 &#x27;ordering&#x27;,\n",
       "                                                                 &#x27;isOriginalTitle&#x27;,\n",
       "                                                                 &#x27;popularity&#x27;,\n",
       "                                                                 &#x27;runtime&#x27;])),\n",
       "                                 (&#x27;categoricalMissingIndicator&#x27;,\n",
       "                                  AddMissingIndicator(variable...\n",
       "                 FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)),\n",
       "                (&#x27;oneHotEncoder&#x27;,\n",
       "                 OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])),\n",
       "                (&#x27;okaycheck2&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)),\n",
       "                (&#x27;removeCategorical&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC0119B1A0&gt;)),\n",
       "                (&#x27;okaycheck3&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC660ADBC0&gt;)),\n",
       "                                 (&#x27;numericalMissingIndicator&#x27;,\n",
       "                                  AddMissingIndicator(variables=[&#x27;runtimeMinutes&#x27;,\n",
       "                                                                 &#x27;seasonNumber&#x27;,\n",
       "                                                                 &#x27;episodeNumber&#x27;,\n",
       "                                                                 &#x27;ordering&#x27;,\n",
       "                                                                 &#x27;isOriginalTitle&#x27;,\n",
       "                                                                 &#x27;popularity&#x27;,\n",
       "                                                                 &#x27;runtime&#x27;])),\n",
       "                                 (&#x27;categoricalMissingIndicator&#x27;,\n",
       "                                  AddMissingIndicator(variable...\n",
       "                 FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)),\n",
       "                (&#x27;oneHotEncoder&#x27;,\n",
       "                 OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])),\n",
       "                (&#x27;okaycheck2&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)),\n",
       "                (&#x27;removeCategorical&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC0119B1A0&gt;)),\n",
       "                (&#x27;okaycheck3&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC660ADBC0&gt;)),\n",
       "                (&#x27;numericalMissingIndicator&#x27;,\n",
       "                 AddMissingIndicator(variables=[&#x27;runtimeMinutes&#x27;,\n",
       "                                                &#x27;seasonNumber&#x27;, &#x27;episodeNumber&#x27;,\n",
       "                                                &#x27;ordering&#x27;, &#x27;isOriginalTitle&#x27;,\n",
       "                                                &#x27;popularity&#x27;, &#x27;runtime&#x27;])),\n",
       "                (&#x27;categoricalMissingIndicator&#x27;,\n",
       "                 AddMissingIndicator(variables=[&#x27;genres_x&#x27;, &#x27;language&#x27;,\n",
       "                                                &#x27;attribu...\n",
       "                                               &#x27;genres_y&#x27;, &#x27;original_language&#x27;,\n",
       "                                               &#x27;production_companies&#x27;,\n",
       "                                               &#x27;production_countries&#x27;, &#x27;status&#x27;,\n",
       "                                               &#x27;tagline&#x27;, &#x27;video&#x27;])),\n",
       "                (&#x27;meanMedianImputer&#x27;,\n",
       "                 MeanMedianImputer(variables=[&#x27;runtimeMinutes&#x27;, &#x27;seasonNumber&#x27;,\n",
       "                                              &#x27;episodeNumber&#x27;, &#x27;ordering&#x27;,\n",
       "                                              &#x27;isOriginalTitle&#x27;, &#x27;popularity&#x27;,\n",
       "                                              &#x27;runtime&#x27;])),\n",
       "                (&#x27;getSTRsFromDicts&#x27;,\n",
       "                 TransformFromDict(variables=[&#x27;production_companies&#x27;,\n",
       "                                              &#x27;production_countries&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC660ADBC0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AddMissingIndicator</label><div class=\"sk-toggleable__content\"><pre>AddMissingIndicator(variables=[&#x27;runtimeMinutes&#x27;, &#x27;seasonNumber&#x27;,\n",
       "                               &#x27;episodeNumber&#x27;, &#x27;ordering&#x27;, &#x27;isOriginalTitle&#x27;,\n",
       "                               &#x27;popularity&#x27;, &#x27;runtime&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AddMissingIndicator</label><div class=\"sk-toggleable__content\"><pre>AddMissingIndicator(variables=[&#x27;genres_x&#x27;, &#x27;language&#x27;, &#x27;attributes&#x27;, &#x27;adult&#x27;,\n",
       "                               &#x27;genres_y&#x27;, &#x27;original_language&#x27;,\n",
       "                               &#x27;production_companies&#x27;, &#x27;production_countries&#x27;,\n",
       "                               &#x27;status&#x27;, &#x27;tagline&#x27;, &#x27;video&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC7C8B8900&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC7C8B8720&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC7C8B89A0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC7C8B8A40&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer(variables=[&#x27;genres_x&#x27;, &#x27;language&#x27;, &#x27;attributes&#x27;, &#x27;adult&#x27;,\n",
       "                              &#x27;genres_y&#x27;, &#x27;original_language&#x27;,\n",
       "                              &#x27;production_companies&#x27;, &#x27;production_countries&#x27;,\n",
       "                              &#x27;status&#x27;, &#x27;tagline&#x27;, &#x27;video&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MeanMedianImputer</label><div class=\"sk-toggleable__content\"><pre>MeanMedianImputer(variables=[&#x27;runtimeMinutes&#x27;, &#x27;seasonNumber&#x27;, &#x27;episodeNumber&#x27;,\n",
       "                             &#x27;ordering&#x27;, &#x27;isOriginalTitle&#x27;, &#x27;popularity&#x27;,\n",
       "                             &#x27;runtime&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TransformFromDict</label><div class=\"sk-toggleable__content\"><pre>TransformFromDict(variables=[&#x27;production_companies&#x27;, &#x27;production_countries&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">exp: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;set_exp_dict_genres&#x27;,\n",
       "                 GetExpDict(categories=[&#x27;genres_x&#x27;, &#x27;titleType&#x27;],\n",
       "                            group=[&#x27;directors&#x27;, &#x27;writers&#x27;,\n",
       "                                   &#x27;production_companies&#x27;,\n",
       "                                   &#x27;production_countries&#x27;],\n",
       "                            simple_only=[&#x27;production_companies&#x27;,\n",
       "                                         &#x27;production_countries&#x27;],\n",
       "                            targets=[&#x27;numVotes&#x27;, &#x27;exp&#x27;, &#x27;runtimeMinutes&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GetExpDict</label><div class=\"sk-toggleable__content\"><pre>GetExpDict(categories=[&#x27;genres_x&#x27;, &#x27;titleType&#x27;],\n",
       "           group=[&#x27;directors&#x27;, &#x27;writers&#x27;, &#x27;production_companies&#x27;,\n",
       "                  &#x27;production_countries&#x27;],\n",
       "           simple_only=[&#x27;production_companies&#x27;, &#x27;production_countries&#x27;],\n",
       "           targets=[&#x27;numVotes&#x27;, &#x27;exp&#x27;, &#x27;runtimeMinutes&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function binarize_genres at 0x000001CC012D54E0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC0119B4C0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001CC0119B1A0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function okay at 0x000001CC012625C0&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('turnToNan',\n",
       "                                  FunctionTransformer(func=<function <lambda> at 0x000001CC660ADBC0>)),\n",
       "                                 ('numericalMissingIndicator',\n",
       "                                  AddMissingIndicator(variables=['runtimeMinutes',\n",
       "                                                                 'seasonNumber',\n",
       "                                                                 'episodeNumber',\n",
       "                                                                 'ordering',\n",
       "                                                                 'isOriginalTitle',\n",
       "                                                                 'popularity',\n",
       "                                                                 'runtime'])),\n",
       "                                 ('categoricalMissingIndicator',\n",
       "                                  AddMissingIndicator(variable...\n",
       "                 FunctionTransformer(func=<function okay at 0x000001CC012625C0>)),\n",
       "                ('oneHotEncoder',\n",
       "                 OneHotEncoder(variables=['titleType', 'status'])),\n",
       "                ('okaycheck2',\n",
       "                 FunctionTransformer(func=<function okay at 0x000001CC012625C0>)),\n",
       "                ('removeCategorical',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x000001CC0119B1A0>)),\n",
       "                ('okaycheck3',\n",
       "                 FunctionTransformer(func=<function okay at 0x000001CC012625C0>))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X,y) #1m 13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay\n",
      "Okay\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Okay\n",
      "Okay\n",
      "Okay\n",
      "Okay\n"
     ]
    }
   ],
   "source": [
    "X_pred = pd.read_csv('dataset/testear.csv').drop(['Unnamed: 0'],axis=1)\n",
    "jjjj = pipeline.transform(X)\n",
    "#293 5m 42.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in jjjj.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "# import cupy as cp\n",
    "# import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a XGBRegressor\n",
      "Finished training the XGBRegressor\n"
     ]
    }
   ],
   "source": [
    "regr = XGBRegressor(n_estimators=1100,eta=0.025,\n",
    "                        max_depth=19,gamma = 0.20,\n",
    "                        colsample_bytree = 0.7,colsample_bylevel=0.7,colsample_bynode=0.8,\n",
    "                        tree_method = 'hist',\n",
    "                        max_cached_hist_node=262144) # type: ignore\n",
    "#regr = XGBRegressor(n_estimators=1200, eta=0.35, max_depth=7, multi_strategy=\"multi_output_tree\", min_child_weight=1, subsample=1, colsample_bytree=1, gamma=0, alpha=0)\n",
    "print(\"Training a XGBRegressor\")\n",
    "regr.fit(jjjj, y)\n",
    "print(\"Finished training the XGBRegressor\")\n",
    "#Tarda 49 minutos con esos settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32ms:\\Github\\preditiva\\pipeline.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m regr \u001b[39m=\u001b[39m XGBRegressor()\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(regr, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(jjjj, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(grid_search\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(grid_search\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1086\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1075\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m (\n\u001b[0;32m   1078\u001b[0m     model,\n\u001b[0;32m   1079\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1085\u001b[0m )\n\u001b[1;32m-> 1086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1087\u001b[0m     params,\n\u001b[0;32m   1088\u001b[0m     train_dmatrix,\n\u001b[0;32m   1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1090\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1091\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1092\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1093\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1094\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1095\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1096\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1097\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1098\u001b[0m )\n\u001b[0;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2048\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2049\u001b[0m     _check_call(\n\u001b[1;32m-> 2050\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[0;32m   2051\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[0;32m   2052\u001b[0m         )\n\u001b[0;32m   2053\u001b[0m     )\n\u001b[0;32m   2054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2055\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [1000, 1500, 2000],\n",
    "    'max_depth': [6, 8, 10,17,19,20],\n",
    "    'gamma':[0.1,0.2,0.3,0.5,0.7,1],\n",
    "    'min_child_weight': [1,2,3,4],\n",
    "}\n",
    "\n",
    "regr = XGBRegressor()\n",
    "grid_search = GridSearchCV(regr, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(jjjj, y)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\"\"\" \n",
    "regr.fit(jjjj, y)\n",
    "regr.score(X_test,y_test) #8 ~ 0.4165 # 5000 y 4 = 0.3958 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "R^2 score on testing data: 0.3928\n",
      "RMSE: 1.095849\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#X_test = pipeline.transform(X_test)\n",
    "print(\"Predicting\")\n",
    "score = regr.score(X_test, y_test) #4797\n",
    "\n",
    "print(f\"R^2 score on testing data: {score:.4f}\") \n",
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "#print(set(X_pred.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pipeline.transform(X_pred)\n",
    "Yest = regr.predict(X_pred).clip(1, 10)\n",
    "salida = pd.DataFrame(data={\"averageRating\": Yest})\n",
    "salida.index = X_pred.index\n",
    "salida.to_csv(\"predicciones/pred40.csv\", sep=',',index=True,  index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
