{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import json,re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from preparando_datos import sum_into_column,split_and_sum,get_min_max,compute_average\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train=pd.read_csv('dataset/origen.csv')\n",
    "#take a 10% sample out of train\n",
    "df_test =  df_train.sample(frac=0.1, random_state=42)\n",
    "#drop the sample from train\n",
    "df_train.drop(df_test.index, inplace=True)\n",
    "\n",
    "X_test = df_test.drop([\"averageRating\",'Unnamed: 0'], axis=1)\n",
    "X = df_train.drop([\"averageRating\",'Unnamed: 0'], axis=1)\n",
    "y = df_train[\"averageRating\"]\n",
    "y_test = df_test['averageRating']\n",
    "\n",
    "del df_test,df_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 879787 entries, 0 to 977540\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   numVotes              879787 non-null  int64  \n",
      " 1   titleType             879787 non-null  object \n",
      " 2   isAdult               879787 non-null  float64\n",
      " 3   startYear             879787 non-null  int64  \n",
      " 4   endYear               879787 non-null  int64  \n",
      " 5   runtimeMinutes        647118 non-null  float64\n",
      " 6   genres_x              879785 non-null  object \n",
      " 7   directors             879787 non-null  object \n",
      " 8   writers               879787 non-null  object \n",
      " 9   seasonNumber          394234 non-null  float64\n",
      " 10  episodeNumber         394234 non-null  float64\n",
      " 11  ordering              333665 non-null  float64\n",
      " 12  language              333665 non-null  object \n",
      " 13  attributes            333665 non-null  object \n",
      " 14  isOriginalTitle       333665 non-null  float64\n",
      " 15  adult                 42627 non-null   object \n",
      " 16  budget                9756 non-null    float64\n",
      " 17  genres_y              42627 non-null   object \n",
      " 18  original_language     42615 non-null   object \n",
      " 19  popularity            42627 non-null   float64\n",
      " 20  production_companies  42627 non-null   object \n",
      " 21  production_countries  42627 non-null   object \n",
      " 22  revenue               8311 non-null    float64\n",
      " 23  runtime               42442 non-null   float64\n",
      " 24  status                42563 non-null   object \n",
      " 25  tagline               21457 non-null   object \n",
      " 26  video                 42627 non-null   object \n",
      "dtypes: float64(10), int64(3), object(14)\n",
      "memory usage: 187.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X['runtimeMinutes'].replace(0, np.nan, inplace=True)\n",
    "X['budget'].replace(0, np.nan, inplace=True)\n",
    "X['revenue'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "print(X.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype == 'O' and X[c].isnull().any()]\n",
    "categorical_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype == 'O' and X[c].notnull().all()]\n",
    "\n",
    "discrete_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].isnull().any()]\n",
    "discrete_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].notnull().all()]\n",
    "\n",
    "\n",
    "numerical_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].isnull().any()]\n",
    "numerical_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].notnull().all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import AddMissingIndicator, CategoricalImputer, MeanMedianImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def interpolate_numericals(df, group, category, method='linear'):\n",
    "    # Fill in missing values using interpolation\n",
    "    df[category].replace(0, np.nan, inplace=True)\n",
    "    df[category].interpolate(method=method, inplace=True)\n",
    "    \n",
    "    # Store the fitted values in a dictionary\n",
    "    if group not in interpolate_numericals.fitted_values:\n",
    "        interpolate_numericals.fitted_values[group] = {}\n",
    "    interpolate_numericals.fitted_values[group][category] = df[category].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Initialize the fitted values dictionary\n",
    "interpolate_numericals.fitted_values = {}\n",
    "\n",
    "pipeline_preprocessing = Pipeline([('numericalMissingIndicator',AddMissingIndicator(variables=numerical_columns_with_nan)),\n",
    "                                   ('runtimeTransform',FunctionTransformer(lambda x: interpolate_numericals(x,'titleType','runtimeMinutes'))),\n",
    "                                   ('budgetTransform',FunctionTransformer(lambda x: interpolate_numericals(x,'titleType','budget'))),\n",
    "                                   ('revenueTransform',FunctionTransformer(lambda x: interpolate_numericals(x,'titleType','revenue'))),\n",
    "                                   ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetExpDict(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group:list, categories:list,targets:list=['']):\n",
    "        if type(group) == str:\n",
    "            group = [group]\n",
    "        if type(categories) == str:\n",
    "            categories = [categories]\n",
    "        if type(targets) == str:\n",
    "            targets = [targets]\n",
    "        \n",
    "        self.group = group\n",
    "        self.categories = categories\n",
    "        self.targets = targets\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        grupos = []\n",
    "        for group in self.group:\n",
    "            for category in self.categories:\n",
    "                for target in self.targets:\n",
    "                    categorias = X[category].unique().tolist()\n",
    "                    categorias = [x.split(',') if type(x) == str else [] for x in categorias]\n",
    "                    categorias = [item for sublist in categorias for item in sublist]\n",
    "                    categorias = list(set(categorias))\n",
    "                    grupo = X.groupby(group).apply(lambda x: [(g, v) for g, v in zip(x[category], x[target] if target!= 'exp' else [1]*len(x))]).to_dict()\n",
    "                    if '0' in grupo:\n",
    "                        del grupo['0']\n",
    "                    grupos.append((group,grupo,categorias,target))\n",
    "        self.diccionarios = Parallel(n_jobs=-1)(delayed(self._fit_group)(group, grupo, categorias,target) for group, grupo, categorias,target in grupos)\n",
    "        return self\n",
    "    \n",
    "    def _fit_group(self, group, grupo, categorias,target):\n",
    "        dict_limpio = {}\n",
    "        for sub_grupo, shows in grupo.items():\n",
    "            for dir in sub_grupo.split(','):\n",
    "                dict_limpio.setdefault(dir, []).extend(shows)\n",
    "\n",
    "        authors_xp = {}\n",
    "        for sub_grupo, values in dict_limpio.items():\n",
    "            cat_counts = {cat: [0, 0] for cat in categorias}\n",
    "            for cat, count in ((v[0], v[1]) for v in values):\n",
    "\n",
    "                if cat in cat_counts:\n",
    "                    cat_counts[cat][0] += count\n",
    "                    cat_counts[cat][1] += 1\n",
    "            \n",
    "            authors_xp[sub_grupo] = {cat: compute_average(cat_counts[cat]) for cat in categorias}\n",
    "\n",
    "        return (group, authors_xp, categorias,target)\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        new_columns = {}\n",
    "        for group, diccionario, categorias, target in self.diccionarios:\n",
    "            for category in categorias:\n",
    "                new_column = f'{group}_{target}_{category}'\n",
    "                new_columns[new_column] = X[group].apply(sum_into_column, args=(diccionario, category,))     \n",
    "        X = pd.concat([X, pd.DataFrame(new_columns)], axis=1)\n",
    "        return X\n",
    "\n",
    "\n",
    "pipeline_exp = Pipeline([\n",
    "    ('set_exp_dict_genres', GetExpDict(group=['directors',\"writers\"], categories=['genres_x'],targets=['numVotes','exp'])),\n",
    "    # add other steps here\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('preprocessing',pipeline_preprocessing),('exp',pipeline_exp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= pipeline.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import cupy as cp\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = XGBRegressor(n_estimators=1100,eta=0.025,\n",
    "                        max_depth=19,gamma = 0.20,\n",
    "                        colsample_bytree = 0.7,colsample_bylevel=0.7,colsample_bynode=0.8,\n",
    "                        tree_method = 'hist',\n",
    "                        max_cached_hist_node=262144) # type: ignore\n",
    "#regr = XGBRegressor(n_estimators=1200, eta=0.35, max_depth=7, multi_strategy=\"multi_output_tree\", min_child_weight=1, subsample=1, colsample_bytree=1, gamma=0, alpha=0)\n",
    "print(\"Training a XGBRegressor\")\n",
    "regr.fit(X, y)\n",
    "print(\"Finished training the XGBRegressor\")\n",
    "\n",
    "score = regr.score(X_test, y_test)\n",
    "\n",
    "print(f\"R^2 score on testing data: {score:.4f}\") \n",
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X_test = pipeline.transform(X_test)\n",
    "y_pred = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "#print(set(X_pred.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
