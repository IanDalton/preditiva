{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json,re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from preparando_datos import sum_into_column,split_and_sum,get_min_max,compute_average,sum_relevant_exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#TODO polars\n",
    "\n",
    "\n",
    "\n",
    "df_train=pd.read_csv('dataset/origen.csv')\n",
    "genre_types = df_train['genres_x'].unique().tolist()\n",
    "\n",
    "genre_types = [genre.split(\",\") if type(genre)==str else ['Missing'] for genre in genre_types]\n",
    "genre_types = [item for sublist in genre_types for item in sublist]\n",
    "genre_types = list(set(genre_types))\n",
    "\n",
    "\n",
    "\n",
    "status_types = df_train['status'].unique().tolist()\n",
    "status_types.remove(np.nan)\n",
    "status_types.append('Missing')\n",
    "status_types.append('Canceled')\n",
    "\"\"\" \n",
    "for i, status in enumerate(status_types):\n",
    "    status_types[i] = f\"status_{status}\" \"\"\"\n",
    "#take a 10% sample out of train\n",
    "df_train.rename(columns={'Unnamed: 0':'exp'}, inplace=True)\n",
    "\n",
    "df_test =  df_train.sample(frac=0.1, random_state=43)\n",
    "#drop the sample from train\n",
    "df_train.drop(df_test.index, inplace=True)\n",
    "\n",
    "X_test = df_test.drop([\"averageRating\"], axis=1)\n",
    "X = df_train.drop([\"averageRating\"], axis=1)\n",
    "#Rename 'Unnamed: 0' to 'exp'\n",
    "\n",
    "\n",
    "y = df_train[\"averageRating\"]\n",
    "y_test = df_test['averageRating']\n",
    "\n",
    "del df_test,df_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(eval(X['production_companies'].iloc[15])[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['runtimeMinutes'].replace(0, np.nan, inplace=True)\n",
    "X['budget'].replace(0, np.nan, inplace=True)\n",
    "X['revenue'].replace(0, np.nan, inplace=True)\n",
    "X['titleType'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan \"[{'iso_3166_1': 'IT', 'name': 'Italy'}]\" '[]' ...\n",
      " \"[{'iso_3166_1': 'FI', 'name': 'Finland'}, {'iso_3166_1': 'EE', 'name': 'Estonia'}, {'iso_3166_1': 'KE', 'name': 'Kenya'}]\"\n",
      " \"[{'iso_3166_1': 'IN', 'name': 'India'}, {'iso_3166_1': 'SE', 'name': 'Sweden'}, {'iso_3166_1': 'RS', 'name': 'Serbia'}, {'iso_3166_1': 'GR', 'name': 'Greece'}]\"\n",
      " \"[{'iso_3166_1': 'BE', 'name': 'Belgium'}, {'iso_3166_1': 'FR', 'name': 'France'}, {'iso_3166_1': 'PT', 'name': 'Portugal'}]\"]\n"
     ]
    }
   ],
   "source": [
    "print(X.production_countries.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype == 'O' and X[c].isnull().any()]\n",
    "\n",
    "categorical_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype == 'O' and X[c].notnull().all()]\n",
    "\n",
    "\n",
    "\n",
    "numerical_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].isnull().any()]\n",
    "numerical_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].notnull().all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformFromDict(BaseEstimator, TransformerMixin):\n",
    "    #Voy a intentar explicar esto lo mejor que puedas\n",
    "    def __init__(self, variables:list):\n",
    "        #\n",
    "        if type(variables) == str:\n",
    "            variables = [variables]     \n",
    "        self.variables = variables\n",
    "\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        def get_str(x):\n",
    "            #x is missing\n",
    "            if x is np.nan or x is None or x == 'Missing' or x == 'nan' or x == '[]' or x == '':\n",
    "                return ''\n",
    "            x = eval(x)\n",
    "            names = []\n",
    "            if type(x)== list:\n",
    "                for item in x:\n",
    "                    if type(item)==dict:\n",
    "                        name = item.get('name', '')\n",
    "                    else:\n",
    "                        name = ''\n",
    "                    names.append(name)\n",
    "            else:\n",
    "                names.append('')\n",
    "            return ','.join(names)\n",
    "        for group in self.variables:\n",
    "            X[group] = X[group].apply(get_str)\n",
    "        return X\n",
    "lista = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import AddMissingIndicator, CategoricalImputer, MeanMedianImputer\n",
    "from feature_engine.encoding import OneHotEncoder,RareLabelEncoder\n",
    "from feature_engine.selection import  DropFeatures\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def interpolate_numericals(df:pd.DataFrame, group, category, method='linear'):\n",
    "    # Fill in missing values using interpolation \n",
    "    interpolated = df.groupby(group)[category].apply(lambda x: x.interpolate(method=method))\n",
    "    \n",
    "    # Reset the index of the interpolated DataFrame\n",
    "    interpolated = interpolated.reset_index(drop=True)\n",
    "    \n",
    "    # Replace the original column with the interpolated column\n",
    "    df[category] = interpolated\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "# Initialize the fitted values dictionary\n",
    "#interpolate_numericals.fitted_values = {}\n",
    "for to_remove in ['budget','revenue']:\n",
    "    try:\n",
    "        numerical_columns_with_nan.remove(to_remove)\n",
    "    except ValueError:\n",
    "        pass \"\"\"\n",
    "\n",
    "def check(x):\n",
    "    print(f\"Number of missing values in titleType before categorical imputer: {x['titleType'].isna().sum()}\")\n",
    "    return x\n",
    "class OverQuantileImputing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables:list, quantiles=4) -> None:\n",
    "        super().__init__()\n",
    "        self.quantiles = quantiles\n",
    "        self.variables = variables\n",
    "        self.thresholds = {}\n",
    "\n",
    "    def fit(self, X:pd.DataFrame, _y=None):\n",
    "        for var in self.variables:\n",
    "            self.thresholds[var] = []\n",
    "            for quantile in range(1, self.quantiles):\n",
    "                self.thresholds[var].append(X[var].quantile(quantile/self.quantiles))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for var in self.variables:\n",
    "            X[f'{var}_quantile'] = 0\n",
    "            for i, threshold in enumerate(self.thresholds[var]):\n",
    "                X.loc[X[var] > threshold, f'{var}_quantile'] = i + 1\n",
    "        return X\n",
    "\n",
    "pipeline_preprocessing = Pipeline([\n",
    "    ('turnToNan', FunctionTransformer(lambda x: x.assign(runtimeMinutes=x['runtimeMinutes'].replace(0, np.nan),\n",
    "                                                          budget=x['budget'].replace(0, np.nan),\n",
    "                                                          revenue=x['revenue'].replace(0, np.nan),\n",
    "                                                          isAdult=x['isAdult'].apply(lambda x: 1 if x>1 else x),\n",
    "                                                          ))),\n",
    "    ('numericalMissingIndicator', AddMissingIndicator(variables=numerical_columns_with_nan)),\n",
    "   ('categoricalMissingIndicator', AddMissingIndicator(variables=categorical_columns_with_nan)),\n",
    "   ('quantileSignaler',OverQuantileImputing(variables=['runtimeMinutes','budget','revenue','numVotes'])),\n",
    "\n",
    "    ('runtimeTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'runtimeMinutes'))),\n",
    "    ('budgetTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'budget'))),\n",
    "    ('revenueTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'revenue'))),\n",
    "    ('endYearsTransform', FunctionTransformer(lambda X: X.assign(endYear=X.apply(lambda x: x['startYear'] if x['endYear'] == 0 else x['endYear'], axis=1)), validate=False)),\n",
    "    ('categoricalImputer', CategoricalImputer(variables=categorical_columns_with_nan,fill_value='Missing')),\n",
    "    ('fill_nans', FunctionTransformer(lambda x: x.assign(video = x['video'].replace('Missing',False),\n",
    "                                                          tagline = x['tagline'].replace('Missing',''),\n",
    "                                                          production_companies = x['production_companies'].replace('Missing',''),\n",
    "                                                            production_countries = x['production_countries'].replace('Missing',''),\n",
    "                                                          ))), \n",
    "    #('meanMedianImputer', MeanMedianImputer(imputation_method='median', variables=numerical_columns_with_nan)),\n",
    "    ('getSTRsFromDicts', TransformFromDict(variables=['production_companies','production_countries'])),\n",
    "    #('tvCategories',RareLabelEncoder(tol=0.01,n_categories=6, variables=['titleType'],replace_with='Other_TV')),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' pipeline_exp = Pipeline([\\n    \\n]) '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#la principal diferencia entre este y el anterior es que el anterior no divide por columnas, sino que muestran unicamente la experiencia en el tag relevante\n",
    "class GetExpDict(BaseEstimator, TransformerMixin):\n",
    "    #Voy a intentar explicar esto lo mejor que puedas\n",
    "    def __init__(self, group:list, categories:list,targets:list=[''],simple_only:list = [],simple_targets:list = []):\n",
    "        super().__init__()\n",
    "        if type(categories) == str:\n",
    "            categories = [categories]\n",
    "        if type(targets) == str:\n",
    "            targets = [targets]\n",
    "        group.extend(simple_only)\n",
    "        targets.extend(simple_targets)\n",
    "        self.group = group\n",
    "        self.categories = {category: [] for category in categories}\n",
    "        self.simple_only = simple_only\n",
    "        self.targets = targets\n",
    "        self.simple_targets = simple_targets\n",
    "\n",
    "    def process_group_category_target(self,group, category, target, X):\n",
    "        #print('Processing group:',group, category, target)\n",
    "        categorias = self.categories[category]\n",
    "        grupo = X.groupby(group).apply(lambda x: [(g, v) for g, v in zip(x[category], x[target] if target== 'exp' else x[category].value_counts())])\n",
    "        #grupo.to_json(f'grupo_{group}_{category}_{target}.json')\n",
    "        grupo = grupo.to_dict()\n",
    "        return (group, grupo, categorias, target)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for category in self.categories:\n",
    "            categorias = X[category].unique().tolist()\n",
    "            categorias = [x.split(',') if type(x) == str else [] for x in categorias]\n",
    "            categorias = [item for sublist in categorias for item in sublist]\n",
    "            categorias = list(set(categorias))\n",
    "            self.categories[category] = categorias\n",
    "        \n",
    "        print(self.group, self.categories, self.targets)\n",
    "        print('creating parallel fitting job')\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.process_group_category_target)(group, category, target, X) for group in self.group for category in self.categories for target in self.targets)\n",
    "        grupos = [result for result in results]\n",
    "        print('done')\n",
    "        self.diccionarios = Parallel(n_jobs=-1)(delayed(self._fit_group)(group, grupo, categorias,target) for group, grupo, categorias,target in grupos)\n",
    "        print('done')\n",
    "        return self\n",
    "    \n",
    "    def _fit_group(self, group, grupo, categorias, target):\n",
    "        # Create a dictionary with directors as keys and their shows as values\n",
    "        \n",
    "        dict_limpio = {}\n",
    "        for sub_grupo, shows in grupo.items():\n",
    "            for dir in sub_grupo.split(','):\n",
    "                dict_limpio[dir] = shows\n",
    "\n",
    "        # Initialize a dictionary to count categories\n",
    "        cat_counts = {}\n",
    "        for sub_grupo in dict_limpio.keys():\n",
    "            cat_counts[sub_grupo] = {}\n",
    "            for cat in categorias:\n",
    "                cat_counts[sub_grupo][cat] = [0, 0]\n",
    "\n",
    "        # Update the count for each category\n",
    "        for sub_grupo, values in dict_limpio.items():\n",
    "            for v in values:\n",
    "                cat = v[0]\n",
    "                count = v[1]\n",
    "                if cat in cat_counts[sub_grupo]:\n",
    "                    cat_counts[sub_grupo][cat][0] += count\n",
    "                    cat_counts[sub_grupo][cat][1] += 1\n",
    "\n",
    "        # Compute the average for each category and store it in authors_xp\n",
    "        authors_xp = {}\n",
    "        for sub_grupo, cat_dict in cat_counts.items():\n",
    "            authors_xp[sub_grupo] = {}\n",
    "            for cat, counts in cat_dict.items():\n",
    "                authors_xp[sub_grupo][cat] = compute_average(counts)\n",
    "        \n",
    "        if '0' in authors_xp:\n",
    "            del authors_xp['0']\n",
    "        if 'Missing' in authors_xp:\n",
    "            del authors_xp['Missing']\n",
    "        if '' in authors_xp:\n",
    "            del authors_xp['']\n",
    "        return group, authors_xp, categorias, target\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Define a helper function for parallel processing\n",
    "        def process_group(group, diccionario, categorias, target):\n",
    "            new_columns = {}\n",
    "            if group not in self.simple_only and target not in self.simple_targets:\n",
    "                new_columns.update({\n",
    "                    f'{group}_{target}_{category}': X[group].apply(sum_into_column, args=(diccionario, category,))\n",
    "                    for category in categorias\n",
    "                })\n",
    "            new_columns.update({\n",
    "                f'{group}_{target}_min': X[group].apply(get_min_max, args=(diccionario, 0, categorias,)),\n",
    "                f'{group}_{target}_max': X[group].apply(get_min_max, args=(diccionario, 1, categorias,)),\n",
    "                f'{group}_{target}_total': X[group].apply(sum_into_column, args=(diccionario, 'total',)),\n",
    "                f'{group}_{target}_relevant': X.apply(sum_relevant_exp, args=(diccionario,group,target), axis=1),\n",
    "            })\n",
    "            return new_columns\n",
    "\n",
    "        # Run the helper function in parallel\n",
    "        results = Parallel(n_jobs=1)(delayed(process_group)(group, diccionario, categorias, target) for group, diccionario, categorias, target in self.diccionarios)\n",
    "\n",
    "        # Combine the results\n",
    "        new_columns = {k: v for result in results for k, v in result.items()}\n",
    "\n",
    "        X = pd.concat([X, pd.DataFrame(new_columns)], axis=1)\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" pipeline_exp = Pipeline([\n",
    "    \n",
    "]) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okay(x):\n",
    "    print(\"Okay\")\n",
    "    return x\n",
    "def binarize_genres(X):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    print('0')\n",
    "    binarized_genres = mlb.fit_transform(X['genres_x'].str.split(','))\n",
    "    df_binarized_genres = pd.DataFrame(binarized_genres, columns=mlb.classes_)\n",
    "    \n",
    "    print('1')\n",
    "    for column in genre_types:\n",
    "        if column not in df_binarized_genres.columns:\n",
    "            df_binarized_genres[column] = 0\n",
    "    print('2')\n",
    "    df_binarized_genres = pd.concat([X, df_binarized_genres], axis=1)\n",
    "    print('3')\n",
    "    return df_binarized_genres\n",
    "\n",
    "#TODO: Comparar a ver si es mejor ni usar order, season y episodeNumber\n",
    "class GetDetailedExp(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, group:dict, targets:dict):\n",
    "        super().__init__()\n",
    "        self.group = group\n",
    "        self.targets = targets\n",
    "\n",
    "    def process_group_target(self,group, target, X):\n",
    "        #print('Processing group:',group, category, target)\n",
    "        objetivos = {}\n",
    "        if self.targets[target]==0:\n",
    "            objetivos[f\"{group}_{target}\"] = X.groupby(group).count()[target].to_dict()\n",
    "\n",
    "        else:\n",
    "            for sub_target in self.targets[target]:\n",
    "                if sub_target:\n",
    "                    mask = X[target] == sub_target\n",
    "                    if mask.any():\n",
    "                        objetivos[f\"{group}_{target}_{sub_target}\"] = X[mask].groupby(group).count()[target].to_dict()\n",
    "                    else:\n",
    "                        print(f\"No rows where target == {sub_target}\")\n",
    "                else:\n",
    "                    objetivos[f\"{group}_{target}_other\"] = X[~X[target].isin(self.targets[target][:-1])].groupby(group).count()[target].to_dict()\n",
    "        \n",
    "        for grupo,diccionario in objetivos.items():\n",
    "            objetivos[grupo] = {\n",
    "                \"datos\" : split_and_sum(diccionario),\n",
    "                \"grupo\": group,\n",
    "            }\n",
    "            if '0' in objetivos[grupo][\"datos\"]:\n",
    "                del objetivos[grupo][\"datos\"]['0']\n",
    "            if 'Missing' in objetivos[grupo][\"datos\"]:\n",
    "                del objetivos[grupo][\"datos\"]['Missing']\n",
    "            if '' in objetivos[grupo][\"datos\"]:\n",
    "                del objetivos[grupo][\"datos\"]['']\n",
    "\n",
    "        \n",
    "        return objetivos\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(self.group, self.targets)\n",
    "        print('creating parallel fitting job')\n",
    "        grupos = dict()\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.process_group_target)(group, target, X) for group in self.group for target in self.targets)\n",
    "        grupos.update({group: result for dictionary in results for group, result in dictionary.items()})\n",
    "        print('done')\n",
    "        self.diccionarios = grupos\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "        def process_group(nombre,diccionario):\n",
    "            return {nombre:X[diccionario['grupo']].apply(sum_into_column, args=(diccionario['datos'],))}\n",
    "            \n",
    "        results = Parallel(n_jobs=-1)(delayed(process_group)(nombre, diccionario) for nombre,diccionario in self.diccionarios.items())\n",
    "\n",
    "        # Combine the results\n",
    "        new_columns = {k: v for result in results for k, v in result.items()}\n",
    "\n",
    "        X = pd.concat([X, pd.DataFrame(new_columns)], axis=1)\n",
    "        return X\n",
    "    \n",
    "\n",
    "\n",
    "pipeline = Pipeline([('preprocessing',pipeline_preprocessing),\n",
    "    ('set_exp_dict_genres', GetExpDict(group=['directors',\"writers\"],\n",
    "                                    categories=['genres_x','titleType'],\n",
    "                                    simple_only=['production_companies','production_countries'],\n",
    "                                    targets=['exp'],\n",
    "                                    simple_targets=['runtimeMinutes','numVotes'])),\n",
    "    ('set_detailed_exp',GetDetailedExp(group=['directors',\"writers\"],\n",
    "                                       targets={'seasonNumber':0,'episodeNumber':0,'titleType':['movie',None]})),\n",
    "\n",
    "    ('binarizeGenres', FunctionTransformer(binarize_genres)),\n",
    "\n",
    "    ('removeEmptyRows', FunctionTransformer(lambda x: x.dropna(subset=['directors']))),\n",
    "\n",
    "    \n",
    "    ('oneHotEncoder', OneHotEncoder(variables=['titleType',\"status\"])),\n",
    "    \n",
    "    ('get_all_companies',FunctionTransformer(lambda x: x.assign(production_companies=x['production_companies'].apply(lambda x: len(x.split(','))),\n",
    "                                                                production_countries=x['production_countries'].apply(lambda x: len(x.split(','))),\n",
    "                                                                directors=x['directors'].apply(lambda x: len(x.split(','))),\n",
    "                                                                writers=x['writers'].apply(lambda x: len(x.split(','))),\n",
    "                                                                tagline=x['tagline'].apply(len),\n",
    "                                                                video = x['video'].astype(int),\n",
    "                                                                budget = x['budget'].fillna(0),\n",
    "                                                                ))),\n",
    "\n",
    "    ('removeCategorical',FunctionTransformer(lambda x: x.drop(x.select_dtypes(include=['object']).columns, axis=1))), \n",
    "    ('removeExpColumn',FunctionTransformer(lambda x: x.drop(['exp'], axis=1))),\n",
    "\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['directors', 'writers', 'production_companies', 'production_countries'] {'genres_x': ['Family', 'Talk-Show', 'History', 'Adventure', 'Action', 'Sport', 'Mystery', 'Comedy', 'Animation', 'Fantasy', 'Reality-TV', 'Musical', 'Short', 'Missing', 'Drama', 'Music', 'Adult', 'Film-Noir', 'Thriller', 'Romance', '0', 'Horror', 'Biography', 'Western', 'News', 'Sci-Fi', 'Game-Show', 'Documentary', 'War', 'Crime'], 'titleType': ['tvSeries', 'videoGame', 'tvMovie', 'tvMiniSeries', 'tvSpecial', 'video', 'tvEpisode', 'short', 'tvShort', 'movie']} ['exp', 'runtimeMinutes', 'numVotes']\n",
      "creating parallel fitting job\n",
      "done\n",
      "done\n",
      "['directors', 'writers'] {'seasonNumber': 0, 'episodeNumber': 0, 'titleType': ['movie', None]}\n",
      "creating parallel fitting job\n",
      "done\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC7A160&gt;)),\n",
       "                                 (&#x27;numericalMissingIndicator&#x27;,\n",
       "                                  AddMissingIndicator(variables=[&#x27;runtimeMinutes&#x27;,\n",
       "                                                                 &#x27;seasonNumber&#x27;,\n",
       "                                                                 &#x27;episodeNumber&#x27;,\n",
       "                                                                 &#x27;ordering&#x27;,\n",
       "                                                                 &#x27;isOriginalTitle&#x27;,\n",
       "                                                                 &#x27;budget&#x27;,\n",
       "                                                                 &#x27;popularity&#x27;,\n",
       "                                                                 &#x27;revenue&#x27;,\n",
       "                                                                 &#x27;runtime&#x27;])),\n",
       "                                 (&#x27;categoricalMissingIndicator&#x27;,\n",
       "                                  AddMissin...\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000289306EDB20&gt;)),\n",
       "                (&#x27;oneHotEncoder&#x27;,\n",
       "                 OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])),\n",
       "                (&#x27;get_all_companies&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x0000028930753380&gt;)),\n",
       "                (&#x27;removeCategorical&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000289307531A0&gt;)),\n",
       "                (&#x27;removeExpColumn&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x0000028930752C00&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC7A160&gt;)),\n",
       "                                 (&#x27;numericalMissingIndicator&#x27;,\n",
       "                                  AddMissingIndicator(variables=[&#x27;runtimeMinutes&#x27;,\n",
       "                                                                 &#x27;seasonNumber&#x27;,\n",
       "                                                                 &#x27;episodeNumber&#x27;,\n",
       "                                                                 &#x27;ordering&#x27;,\n",
       "                                                                 &#x27;isOriginalTitle&#x27;,\n",
       "                                                                 &#x27;budget&#x27;,\n",
       "                                                                 &#x27;popularity&#x27;,\n",
       "                                                                 &#x27;revenue&#x27;,\n",
       "                                                                 &#x27;runtime&#x27;])),\n",
       "                                 (&#x27;categoricalMissingIndicator&#x27;,\n",
       "                                  AddMissin...\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000289306EDB20&gt;)),\n",
       "                (&#x27;oneHotEncoder&#x27;,\n",
       "                 OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])),\n",
       "                (&#x27;get_all_companies&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x0000028930753380&gt;)),\n",
       "                (&#x27;removeCategorical&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000289307531A0&gt;)),\n",
       "                (&#x27;removeExpColumn&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x0000028930752C00&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC7A160&gt;)),\n",
       "                (&#x27;numericalMissingIndicator&#x27;,\n",
       "                 AddMissingIndicator(variables=[&#x27;runtimeMinutes&#x27;,\n",
       "                                                &#x27;seasonNumber&#x27;, &#x27;episodeNumber&#x27;,\n",
       "                                                &#x27;ordering&#x27;, &#x27;isOriginalTitle&#x27;,\n",
       "                                                &#x27;budget&#x27;, &#x27;popularity&#x27;,\n",
       "                                                &#x27;revenue&#x27;, &#x27;runtime&#x27;])),\n",
       "                (&#x27;categoricalMissingIndicator&#x27;,\n",
       "                 AddMissingIndicator(variables=[&#x27;genres_x&#x27;,...\n",
       "                 CategoricalImputer(variables=[&#x27;genres_x&#x27;, &#x27;language&#x27;,\n",
       "                                               &#x27;attributes&#x27;, &#x27;adult&#x27;,\n",
       "                                               &#x27;genres_y&#x27;, &#x27;original_language&#x27;,\n",
       "                                               &#x27;production_companies&#x27;,\n",
       "                                               &#x27;production_countries&#x27;, &#x27;status&#x27;,\n",
       "                                               &#x27;tagline&#x27;, &#x27;video&#x27;])),\n",
       "                (&#x27;fill_nans&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC79080&gt;)),\n",
       "                (&#x27;getSTRsFromDicts&#x27;,\n",
       "                 TransformFromDict(variables=[&#x27;production_companies&#x27;,\n",
       "                                              &#x27;production_countries&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC7A160&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AddMissingIndicator</label><div class=\"sk-toggleable__content\"><pre>AddMissingIndicator(variables=[&#x27;runtimeMinutes&#x27;, &#x27;seasonNumber&#x27;,\n",
       "                               &#x27;episodeNumber&#x27;, &#x27;ordering&#x27;, &#x27;isOriginalTitle&#x27;,\n",
       "                               &#x27;budget&#x27;, &#x27;popularity&#x27;, &#x27;revenue&#x27;, &#x27;runtime&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AddMissingIndicator</label><div class=\"sk-toggleable__content\"><pre>AddMissingIndicator(variables=[&#x27;genres_x&#x27;, &#x27;language&#x27;, &#x27;attributes&#x27;, &#x27;adult&#x27;,\n",
       "                               &#x27;genres_y&#x27;, &#x27;original_language&#x27;,\n",
       "                               &#x27;production_companies&#x27;, &#x27;production_countries&#x27;,\n",
       "                               &#x27;status&#x27;, &#x27;tagline&#x27;, &#x27;video&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OverQuantileImputing</label><div class=\"sk-toggleable__content\"><pre>OverQuantileImputing(variables=[&#x27;runtimeMinutes&#x27;, &#x27;budget&#x27;, &#x27;revenue&#x27;,\n",
       "                                &#x27;numVotes&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC79F80&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC799E0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC79620&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC794E0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer(variables=[&#x27;genres_x&#x27;, &#x27;language&#x27;, &#x27;attributes&#x27;, &#x27;adult&#x27;,\n",
       "                              &#x27;genres_y&#x27;, &#x27;original_language&#x27;,\n",
       "                              &#x27;production_companies&#x27;, &#x27;production_countries&#x27;,\n",
       "                              &#x27;status&#x27;, &#x27;tagline&#x27;, &#x27;video&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000288BEC79080&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TransformFromDict</label><div class=\"sk-toggleable__content\"><pre>TransformFromDict(variables=[&#x27;production_companies&#x27;, &#x27;production_countries&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GetExpDict</label><div class=\"sk-toggleable__content\"><pre>GetExpDict(categories={&#x27;genres_x&#x27;: [&#x27;Family&#x27;, &#x27;Talk-Show&#x27;, &#x27;History&#x27;,\n",
       "                                    &#x27;Adventure&#x27;, &#x27;Action&#x27;, &#x27;Sport&#x27;, &#x27;Mystery&#x27;,\n",
       "                                    &#x27;Comedy&#x27;, &#x27;Animation&#x27;, &#x27;Fantasy&#x27;,\n",
       "                                    &#x27;Reality-TV&#x27;, &#x27;Musical&#x27;, &#x27;Short&#x27;, &#x27;Missing&#x27;,\n",
       "                                    &#x27;Drama&#x27;, &#x27;Music&#x27;, &#x27;Adult&#x27;, &#x27;Film-Noir&#x27;,\n",
       "                                    &#x27;Thriller&#x27;, &#x27;Romance&#x27;, &#x27;0&#x27;, &#x27;Horror&#x27;,\n",
       "                                    &#x27;Biography&#x27;, &#x27;Western&#x27;, &#x27;News&#x27;, &#x27;Sci-Fi&#x27;,\n",
       "                                    &#x27;Game-Show&#x27;, &#x27;Documentary&#x27;, &#x27;War&#x27;,\n",
       "                                    &#x27;Crime&#x27;],\n",
       "                       &#x27;titleType&#x27;: [&#x27;tvSeries&#x27;, &#x27;videoGame&#x27;, &#x27;tvMovie&#x27;,\n",
       "                                     &#x27;tvMiniSeries&#x27;, &#x27;tvSpecial&#x27;, &#x27;video&#x27;,\n",
       "                                     &#x27;tvEpisode&#x27;, &#x27;short&#x27;, &#x27;tvShort&#x27;,\n",
       "                                     &#x27;movie&#x27;]},\n",
       "           group=[&#x27;directors&#x27;, &#x27;writers&#x27;, &#x27;production_companies&#x27;,\n",
       "                  &#x27;production_countries&#x27;],\n",
       "           simple_only=[&#x27;production_companies&#x27;, &#x27;production_countries&#x27;],\n",
       "           simple_targets=[&#x27;runtimeMinutes&#x27;, &#x27;numVotes&#x27;],\n",
       "           targets=[&#x27;exp&#x27;, &#x27;runtimeMinutes&#x27;, &#x27;numVotes&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GetDetailedExp</label><div class=\"sk-toggleable__content\"><pre>GetDetailedExp(group=[&#x27;directors&#x27;, &#x27;writers&#x27;],\n",
       "               targets={&#x27;episodeNumber&#x27;: 0, &#x27;seasonNumber&#x27;: 0,\n",
       "                        &#x27;titleType&#x27;: [&#x27;movie&#x27;, None]})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function binarize_genres at 0x00000288BEC12020&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000289306EDB20&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x0000028930753380&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000289307531A0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x0000028930752C00&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('turnToNan',\n",
       "                                  FunctionTransformer(func=<function <lambda> at 0x00000288BEC7A160>)),\n",
       "                                 ('numericalMissingIndicator',\n",
       "                                  AddMissingIndicator(variables=['runtimeMinutes',\n",
       "                                                                 'seasonNumber',\n",
       "                                                                 'episodeNumber',\n",
       "                                                                 'ordering',\n",
       "                                                                 'isOriginalTitle',\n",
       "                                                                 'budget',\n",
       "                                                                 'popularity',\n",
       "                                                                 'revenue',\n",
       "                                                                 'runtime'])),\n",
       "                                 ('categoricalMissingIndicator',\n",
       "                                  AddMissin...\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x00000289306EDB20>)),\n",
       "                ('oneHotEncoder',\n",
       "                 OneHotEncoder(variables=['titleType', 'status'])),\n",
       "                ('get_all_companies',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x0000028930753380>)),\n",
       "                ('removeCategorical',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x00000289307531A0>)),\n",
       "                ('removeExpColumn',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x0000028930752C00>))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X,y) #4m 30.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32ms:\\Github\\preditiva\\pipeline.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#X_pred = pd.read_csv('dataset/testear.csv').drop(['Unnamed: 0'],axis=1)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m jjjj \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#293 3m 42.8\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:696\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    694\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[0;32m    695\u001b[0m \u001b[39mfor\u001b[39;00m _, _, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter():\n\u001b[1;32m--> 696\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[0;32m    697\u001b[0m \u001b[39mreturn\u001b[39;00m Xt\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "\u001b[1;32ms:\\Github\\preditiva\\pipeline.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m new_columns\n\u001b[0;32m    <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39m# Run the helper function in parallel\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m results \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)(delayed(process_group)(group, diccionario, categorias, target) \u001b[39mfor\u001b[39;49;00m group, diccionario, categorias, target \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiccionarios)\n\u001b[0;32m    <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m# Combine the results\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m new_columns \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "\u001b[1;32ms:\\Github\\preditiva\\pipeline.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mif\u001b[39;00m group \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimple_only \u001b[39mand\u001b[39;00m target \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimple_targets:\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     new_columns\u001b[39m.\u001b[39mupdate({\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mgroup\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcategory\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m: X[group]\u001b[39m.\u001b[39mapply(sum_into_column, args\u001b[39m=\u001b[39m(diccionario, category,))\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m         \u001b[39mfor\u001b[39;00m category \u001b[39min\u001b[39;00m categorias\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     })\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m new_columns\u001b[39m.\u001b[39mupdate({\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mgroup\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m_min\u001b[39m\u001b[39m'\u001b[39m: X[group]\u001b[39m.\u001b[39mapply(get_min_max, args\u001b[39m=\u001b[39m(diccionario, \u001b[39m0\u001b[39m, categorias,)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mgroup\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m_max\u001b[39m\u001b[39m'\u001b[39m: X[group]\u001b[39m.\u001b[39mapply(get_min_max, args\u001b[39m=\u001b[39m(diccionario, \u001b[39m1\u001b[39m, categorias,)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mgroup\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m_total\u001b[39m\u001b[39m'\u001b[39m: X[group]\u001b[39m.\u001b[39mapply(sum_into_column, args\u001b[39m=\u001b[39m(diccionario, \u001b[39m'\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m'\u001b[39m,)),\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mgroup\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m_relevant\u001b[39m\u001b[39m'\u001b[39m: X\u001b[39m.\u001b[39;49mapply(sum_relevant_exp, args\u001b[39m=\u001b[39;49m(diccionario,group,target), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m })\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/pipeline.ipynb#X42sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39mreturn\u001b[39;00m new_columns\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m  10022\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10024\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m  10025\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  10026\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10032\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m  10033\u001b[0m )\n\u001b[1;32m> 10034\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    835\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 837\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 963\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    965\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    966\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    977\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    978\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 979\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(v, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[0;32m    980\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    981\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    982\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    983\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32ms:\\Github\\preditiva\\preparando_datos.py:50\u001b[0m, in \u001b[0;36msum_relevant_exp\u001b[1;34m(persons, data, group, target)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 total_person \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m data[person][cat]\n\u001b[0;32m     49\u001b[0m                 total_cat \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m data[person][cat] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 50\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_person \u001b[39m/\u001b[39m total_cat \u001b[39mif\u001b[39;00m total_cat \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m total\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(personas)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#X_pred = pd.read_csv('dataset/testear.csv').drop(['Unnamed: 0'],axis=1)\n",
    "jjjj = pipeline.transform(X)\n",
    "\n",
    "#293 3m 42.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the target\n",
    "\"\"\" jjjj['averageRating'] = y\n",
    "jjjj.to_csv('dataset/transformedd.csv') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test2 = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "# import cupy as cp\n",
    "# import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = XGBRegressor(n_estimators=1100,eta=0.05,\n",
    "                        max_depth=20,gamma = 0.20,\n",
    "                        colsample_bytree = 0.7,colsample_bylevel=0.7,colsample_bynode=0.8,\n",
    "                        tree_method = 'hist',\n",
    "                        max_cached_hist_node=262144) # type: ignore\n",
    "#regr = XGBRegressor(n_estimators=1200, eta=0.35, max_depth=7, multi_strategy=\"multi_output_tree\", min_child_weight=1, subsample=1, colsample_bytree=1, gamma=0, alpha=0)\n",
    "print(\"Training a XGBRegressor\")\n",
    "regr.fit(jjjj, y)\n",
    "print(\"Finished training the XGBRegressor\")\n",
    "#Tarda 49 minutos con esos settings 4565\n",
    "regr.score(pipeline.transform(X_test),y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lrerg = LGBMRegressor(n_estimators=5000,learning_rate=0.2)\n",
    "lrerg.fit(pipeline.transform(X), y)\n",
    "lrerg.score(pipeline.transform(X_test),y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [1000, 1500, 2000],\n",
    "    'max_depth': [6, 8, 10,17,19,20],\n",
    "    'gamma':[0.1,0.2,0.3,0.5,0.7,1],\n",
    "    'min_child_weight': [1,2,3,4],\n",
    "}\n",
    "\n",
    "regr = XGBRegressor()\n",
    "grid_search = RandomizedSearchCV(regr, param_grid,n_iter=100, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(jjjj, y)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\"\"\" \n",
    "regr.fit(jjjj, y)\n",
    "regr.score(X_test,y_test) #8 ~ 0.4165 # 5000 y 4 = 0.3958 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_test = pipeline.transform(X_test)\n",
    "print(\"Predicting\")\n",
    "score = regr.score(X_test, y_test) #4797\n",
    "\n",
    "print(f\"R^2 score on testing data: {score:.4f}\") \n",
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "#print(set(X_pred.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pd.read_csv('dataset/testear.csv').rename(columns={'Unnamed: 0':'exp'})\n",
    "\n",
    "X_pred = pipeline.transform(X_pred)\n",
    "Yest = regr.predict(X_pred).clip(1, 10)\n",
    "salida = pd.DataFrame(data={\"averageRating\": Yest})\n",
    "salida.index = X_pred.index\n",
    "salida.to_csv(\"predicciones/pred40.csv\", sep=',',index=True,  index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
