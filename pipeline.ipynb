{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json,re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from preparando_datos import sum_into_column,split_and_sum,get_min_max,compute_average,sum_relevant_exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#TODO polars\n",
    "\n",
    "\n",
    "\n",
    "df_train=pd.read_csv('dataset/origen.csv')\n",
    "genre_types = df_train['genres_x'].unique().tolist()\n",
    "\n",
    "genre_types = [genre.split(\",\") if type(genre)==str else ['Missing'] for genre in genre_types]\n",
    "genre_types = [item for sublist in genre_types for item in sublist]\n",
    "genre_types = list(set(genre_types))\n",
    "\n",
    "\n",
    "\n",
    "status_types = df_train['status'].unique().tolist()\n",
    "status_types.remove(np.nan)\n",
    "status_types.append('Missing')\n",
    "status_types.append('Canceled')\n",
    "\"\"\" \n",
    "for i, status in enumerate(status_types):\n",
    "    status_types[i] = f\"status_{status}\" \"\"\"\n",
    "#take a 10% sample out of train\n",
    "df_train.rename(columns={'Unnamed: 0':'exp'}, inplace=True)\n",
    "\n",
    "df_test =  df_train.sample(frac=0.1, random_state=43)\n",
    "#drop the sample from train\n",
    "df_train.drop(df_test.index, inplace=True)\n",
    "\n",
    "X_test = df_test.drop([\"averageRating\"], axis=1)\n",
    "X = df_train.drop([\"averageRating\"], axis=1)\n",
    "#Rename 'Unnamed: 0' to 'exp'\n",
    "\n",
    "\n",
    "y = df_train[\"averageRating\"]\n",
    "y_test = df_test['averageRating']\n",
    "\n",
    "del df_test,df_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(eval(X['production_companies'].iloc[15])[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['runtimeMinutes'].replace(0, np.nan, inplace=True)\n",
    "X['budget'].replace(0, np.nan, inplace=True)\n",
    "X['revenue'].replace(0, np.nan, inplace=True)\n",
    "X['titleType'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan \"[{'iso_3166_1': 'IT', 'name': 'Italy'}]\" '[]' ...\n",
      " \"[{'iso_3166_1': 'FI', 'name': 'Finland'}, {'iso_3166_1': 'EE', 'name': 'Estonia'}, {'iso_3166_1': 'KE', 'name': 'Kenya'}]\"\n",
      " \"[{'iso_3166_1': 'IN', 'name': 'India'}, {'iso_3166_1': 'SE', 'name': 'Sweden'}, {'iso_3166_1': 'RS', 'name': 'Serbia'}, {'iso_3166_1': 'GR', 'name': 'Greece'}]\"\n",
      " \"[{'iso_3166_1': 'BE', 'name': 'Belgium'}, {'iso_3166_1': 'FR', 'name': 'France'}, {'iso_3166_1': 'PT', 'name': 'Portugal'}]\"]\n"
     ]
    }
   ],
   "source": [
    "print(X.production_countries.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype == 'O' and X[c].isnull().any()]\n",
    "\n",
    "categorical_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype == 'O' and X[c].notnull().all()]\n",
    "\n",
    "\n",
    "\n",
    "numerical_columns_with_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].isnull().any()]\n",
    "numerical_columns_without_nan = [\n",
    "    c for c in X.columns if X[c].dtype != 'O' and X[c].notnull().all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformFromDict(BaseEstimator, TransformerMixin):\n",
    "    #Voy a intentar explicar esto lo mejor que puedas\n",
    "    def __init__(self, variables:list):\n",
    "        #\n",
    "        if type(variables) == str:\n",
    "            variables = [variables]     \n",
    "        self.variables = variables\n",
    "\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        def get_str(x):\n",
    "            #x is missing\n",
    "            if x is np.nan or x is None or x == 'Missing' or x == 'nan' or x == '[]' or x == '':\n",
    "                return ''\n",
    "            x = eval(x)\n",
    "            names = []\n",
    "            if type(x)== list:\n",
    "                for item in x:\n",
    "                    if type(item)==dict:\n",
    "                        name = item.get('name', '')\n",
    "                    else:\n",
    "                        name = ''\n",
    "                    names.append(name)\n",
    "            else:\n",
    "                names.append('')\n",
    "            return ','.join(names)\n",
    "        for group in self.variables:\n",
    "            X[group] = X[group].apply(get_str)\n",
    "        return X\n",
    "lista = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.imputation import AddMissingIndicator, CategoricalImputer, MeanMedianImputer\n",
    "from feature_engine.encoding import OneHotEncoder,RareLabelEncoder\n",
    "from feature_engine.selection import  DropFeatures\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def interpolate_numericals(df, group, category, method='linear'):\n",
    "    # Fill in missing values using interpolation\n",
    "    df[category].replace(0, np.nan, inplace=True)\n",
    "    df[category].interpolate(method=method, inplace=True)\n",
    "    \n",
    "    # Store the fitted values in a dictionary\n",
    "    if group not in interpolate_numericals.fitted_values:\n",
    "        interpolate_numericals.fitted_values[group] = {}\n",
    "    interpolate_numericals.fitted_values[group][category] = df[category].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Initialize the fitted values dictionary\n",
    "interpolate_numericals.fitted_values = {}\n",
    "for to_remove in ['budget','revenue']:\n",
    "    try:\n",
    "        numerical_columns_with_nan.remove(to_remove)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "def check(x):\n",
    "    print(f\"Number of missing values in titleType before categorical imputer: {x['titleType'].isna().sum()}\")\n",
    "    return x\n",
    "\n",
    "pipeline_preprocessing = Pipeline([\n",
    "    ('turnToNan', FunctionTransformer(lambda x: x.assign(runtimeMinutes=x['runtimeMinutes'].replace(0, np.nan),\n",
    "                                                          budget=x['budget'].replace(0, np.nan),\n",
    "                                                          revenue=x['revenue'].replace(0, np.nan),\n",
    "                                                          isAdult=x['isAdult'].apply(lambda x: 1 if x>1 else x),\n",
    "                                                          ))),\n",
    "    ('numericalMissingIndicator', AddMissingIndicator(variables=numerical_columns_with_nan)),\n",
    "   ('categoricalMissingIndicator', AddMissingIndicator(variables=categorical_columns_with_nan)),\n",
    "\n",
    "    ('runtimeTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'runtimeMinutes'))),\n",
    "    ('budgetTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'budget'))),\n",
    "    ('revenueTransform', FunctionTransformer(lambda x: interpolate_numericals(x, 'titleType', 'revenue'))),\n",
    "    ('endYearsTransform', FunctionTransformer(lambda X: X.assign(endYear=X.apply(lambda x: x['startYear'] if x['endYear'] == 0 else x['endYear'], axis=1)), validate=False)),\n",
    "    ('categoricalImputer', CategoricalImputer(variables=categorical_columns_with_nan,fill_value='Missing')),\n",
    "    ('fill_nans', FunctionTransformer(lambda x: x.assign(video = x['video'].replace('Missing',False),\n",
    "                                                          tagline = x['tagline'].replace('Missing',''),\n",
    "                                                          production_companies = x['production_companies'].replace('Missing',''),\n",
    "                                                            production_countries = x['production_countries'].replace('Missing',''),\n",
    "                                                          ))), \n",
    "    #('meanMedianImputer', MeanMedianImputer(imputation_method='median', variables=numerical_columns_with_nan)),\n",
    "    ('getSTRsFromDicts', TransformFromDict(variables=['production_companies','production_countries'])),\n",
    "    #('tvCategories',RareLabelEncoder(tol=0.01,n_categories=6, variables=['titleType'],replace_with='Other_TV')),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' pipeline_exp = Pipeline([\\n    \\n]) '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#la principal diferencia entre este y el anterior es que el anterior no divide por columnas, sino que muestran unicamente la experiencia en el tag relevante\n",
    "class GetExpDict(BaseEstimator, TransformerMixin):\n",
    "    #Voy a intentar explicar esto lo mejor que puedas\n",
    "    def __init__(self, group:list, categories:list,targets:list=[''],simple_only:list = [],simple_targets:list = []):\n",
    "        super().__init__()\n",
    "        if type(categories) == str:\n",
    "            categories = [categories]\n",
    "        if type(targets) == str:\n",
    "            targets = [targets]\n",
    "        group.extend(simple_only)\n",
    "        targets.extend(simple_targets)\n",
    "        self.group = group\n",
    "        self.categories = {category: [] for category in categories}\n",
    "        self.simple_only = simple_only\n",
    "        self.targets = targets\n",
    "        self.simple_targets = simple_targets\n",
    "\n",
    "    def process_group_category_target(self,group, category, target, X):\n",
    "        #print('Processing group:',group, category, target)\n",
    "        categorias = self.categories[category]\n",
    "        grupo = X.groupby(group).apply(lambda x: [(g, v) for g, v in zip(x[category], x[target] if target== 'exp' else x[category].value_counts())])\n",
    "        #grupo.to_json(f'grupo_{group}_{category}_{target}.json')\n",
    "        grupo = grupo.to_dict()\n",
    "        return (group, grupo, categorias, target)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for category in self.categories:\n",
    "            categorias = X[category].unique().tolist()\n",
    "            categorias = [x.split(',') if type(x) == str else [] for x in categorias]\n",
    "            categorias = [item for sublist in categorias for item in sublist]\n",
    "            categorias = list(set(categorias))\n",
    "            self.categories[category] = categorias\n",
    "        \n",
    "        print(self.group, self.categories, self.targets)\n",
    "        print('creating parallel fitting job')\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.process_group_category_target)(group, category, target, X) for group in self.group for category in self.categories for target in self.targets)\n",
    "        grupos = [result for result in results]\n",
    "        print('done')\n",
    "        self.diccionarios = Parallel(n_jobs=-1)(delayed(self._fit_group)(group, grupo, categorias,target) for group, grupo, categorias,target in grupos)\n",
    "        print('done')\n",
    "        return self\n",
    "    \n",
    "    def _fit_group(self, group, grupo, categorias, target):\n",
    "        # Create a dictionary with directors as keys and their shows as values\n",
    "        \n",
    "        dict_limpio = {}\n",
    "        for sub_grupo, shows in grupo.items():\n",
    "            for dir in sub_grupo.split(','):\n",
    "                dict_limpio[dir] = shows\n",
    "\n",
    "        # Initialize a dictionary to count categories\n",
    "        cat_counts = {}\n",
    "        for sub_grupo in dict_limpio.keys():\n",
    "            cat_counts[sub_grupo] = {}\n",
    "            for cat in categorias:\n",
    "                cat_counts[sub_grupo][cat] = [0, 0]\n",
    "\n",
    "        # Update the count for each category\n",
    "        for sub_grupo, values in dict_limpio.items():\n",
    "            for v in values:\n",
    "                cat = v[0]\n",
    "                count = v[1]\n",
    "                if cat in cat_counts[sub_grupo]:\n",
    "                    cat_counts[sub_grupo][cat][0] += count\n",
    "                    cat_counts[sub_grupo][cat][1] += 1\n",
    "\n",
    "        # Compute the average for each category and store it in authors_xp\n",
    "        authors_xp = {}\n",
    "        for sub_grupo, cat_dict in cat_counts.items():\n",
    "            authors_xp[sub_grupo] = {}\n",
    "            for cat, counts in cat_dict.items():\n",
    "                authors_xp[sub_grupo][cat] = compute_average(counts)\n",
    "        \n",
    "        if '0' in authors_xp:\n",
    "            del authors_xp['0']\n",
    "        if 'Missing' in authors_xp:\n",
    "            del authors_xp['Missing']\n",
    "        if '' in authors_xp:\n",
    "            del authors_xp['']\n",
    "        return group, authors_xp, categorias, target\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Define a helper function for parallel processing\n",
    "        def process_group(group, diccionario, categorias, target):\n",
    "            new_columns = {}\n",
    "            if group not in self.simple_only and target not in self.simple_targets:\n",
    "                new_columns.update({\n",
    "                    f'{group}_{target}_{category}': X[group].apply(sum_into_column, args=(diccionario, category,))\n",
    "                    for category in categorias\n",
    "                })\n",
    "            new_columns.update({\n",
    "                f'{group}_{target}_min': X[group].apply(get_min_max, args=(diccionario, 0, categorias,)),\n",
    "                f'{group}_{target}_max': X[group].apply(get_min_max, args=(diccionario, 1, categorias,)),\n",
    "                f'{group}_{target}_total': X[group].apply(sum_into_column, args=(diccionario, 'total',)),\n",
    "                f'{group}_{target}_relevant': X.apply(sum_relevant_exp, args=(diccionario,group,target), axis=1),\n",
    "            })\n",
    "            return new_columns\n",
    "\n",
    "        # Run the helper function in parallel\n",
    "        results = Parallel(n_jobs=1)(delayed(process_group)(group, diccionario, categorias, target) for group, diccionario, categorias, target in self.diccionarios)\n",
    "\n",
    "        # Combine the results\n",
    "        new_columns = {k: v for result in results for k, v in result.items()}\n",
    "\n",
    "        X = pd.concat([X, pd.DataFrame(new_columns)], axis=1)\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" pipeline_exp = Pipeline([\n",
    "    \n",
    "]) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okay(x):\n",
    "    print(\"Okay\")\n",
    "    return x\n",
    "def binarize_genres(X):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    print('0')\n",
    "    binarized_genres = mlb.fit_transform(X['genres_x'].str.split(','))\n",
    "    df_binarized_genres = pd.DataFrame(binarized_genres, columns=mlb.classes_)\n",
    "    \n",
    "    print('1')\n",
    "    for column in genre_types:\n",
    "        if column not in df_binarized_genres.columns:\n",
    "            df_binarized_genres[column] = 0\n",
    "    print('2')\n",
    "    df_binarized_genres = pd.concat([X, df_binarized_genres], axis=1)\n",
    "    print('3')\n",
    "    return df_binarized_genres\n",
    "\n",
    "#TODO: Comparar a ver si es mejor ni usar order, season y episodeNumber\n",
    "class GetDetailedExp(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, group:dict, targets:dict):\n",
    "        super().__init__()\n",
    "        self.group = group\n",
    "        self.targets = targets\n",
    "\n",
    "    def process_group_target(self,group, target, X):\n",
    "        #print('Processing group:',group, category, target)\n",
    "        objetivos = {}\n",
    "        if self.targets[target]==0:\n",
    "            objetivos[f\"{group}_{target}\"] = X.groupby(group).count()[target].to_dict()\n",
    "\n",
    "        else:\n",
    "            for sub_target in self.targets[target]:\n",
    "                if sub_target:\n",
    "                    mask = X[target] == sub_target\n",
    "                    if mask.any():\n",
    "                        objetivos[f\"{group}_{target}_{sub_target}\"] = X[mask].groupby(group).count()[target].to_dict()\n",
    "                    else:\n",
    "                        print(f\"No rows where target == {sub_target}\")\n",
    "                else:\n",
    "                    objetivos[f\"{group}_{target}_other\"] = X[~X[target].isin(self.targets[target][:-1])].groupby(group).count()[target].to_dict()\n",
    "        \n",
    "        for grupo,diccionario in objetivos.items():\n",
    "            objetivos[grupo] = {\n",
    "                \"datos\" : split_and_sum(diccionario),\n",
    "                \"grupo\": group,\n",
    "            }\n",
    "            if '0' in objetivos[grupo][\"datos\"]:\n",
    "                del objetivos[grupo][\"datos\"]['0']\n",
    "            if 'Missing' in objetivos[grupo][\"datos\"]:\n",
    "                del objetivos[grupo][\"datos\"]['Missing']\n",
    "            if '' in objetivos[grupo][\"datos\"]:\n",
    "                del objetivos[grupo][\"datos\"]['']\n",
    "\n",
    "        \n",
    "        return objetivos\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(self.group, self.targets)\n",
    "        print('creating parallel fitting job')\n",
    "        grupos = dict()\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.process_group_target)(group, target, X) for group in self.group for target in self.targets)\n",
    "        grupos.update({group: result for dictionary in results for group, result in dictionary.items()})\n",
    "        print('done')\n",
    "        self.diccionarios = grupos\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "        def process_group(nombre,diccionario):\n",
    "            return {nombre:X[diccionario['grupo']].apply(sum_into_column, args=(diccionario['datos'],))}\n",
    "            \n",
    "        results = Parallel(n_jobs=-1)(delayed(process_group)(nombre, diccionario) for nombre,diccionario in self.diccionarios.items())\n",
    "\n",
    "        # Combine the results\n",
    "        new_columns = {k: v for result in results for k, v in result.items()}\n",
    "\n",
    "        X = pd.concat([X, pd.DataFrame(new_columns)], axis=1)\n",
    "        return X\n",
    "    \n",
    "\n",
    "\n",
    "pipeline = Pipeline([('preprocessing',pipeline_preprocessing),\n",
    "    ('set_exp_dict_genres', GetExpDict(group=['directors',\"writers\"],\n",
    "                                    categories=['genres_x','titleType'],\n",
    "                                    simple_only=['production_companies','production_countries'],\n",
    "                                    targets=['exp'],\n",
    "                                    simple_targets=['runtimeMinutes','numVotes'])),\n",
    "    ('set_detailed_exp',GetDetailedExp(group=['directors',\"writers\"],\n",
    "                                       targets={'seasonNumber':0,'episodeNumber':0,'titleType':['movie',None]})),\n",
    "\n",
    "    ('binarizeGenres', FunctionTransformer(binarize_genres)),\n",
    "\n",
    "    ('removeEmptyRows', FunctionTransformer(lambda x: x.dropna(subset=['directors']))),\n",
    "\n",
    "    \n",
    "    ('oneHotEncoder', OneHotEncoder(variables=['titleType',\"status\"])),\n",
    "    \n",
    "    ('get_all_companies',FunctionTransformer(lambda x: x.assign(production_companies=x['production_companies'].apply(lambda x: len(x.split(','))),\n",
    "                                                                production_countries=x['production_countries'].apply(lambda x: len(x.split(','))),\n",
    "                                                                directors=x['directors'].apply(lambda x: len(x.split(','))),\n",
    "                                                                writers=x['writers'].apply(lambda x: len(x.split(','))),\n",
    "                                                                tagline=x['tagline'].apply(len),\n",
    "                                                                video = x['video'].astype(int),\n",
    "                                                                budget = x['budget'].fillna(0),\n",
    "                                                                ))),\n",
    "\n",
    "    ('removeCategorical',FunctionTransformer(lambda x: x.drop(x.select_dtypes(include=['object']).columns, axis=1))), \n",
    "    ('removeExpColumn',FunctionTransformer(lambda x: x.drop(['exp'], axis=1))),\n",
    "\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['directors', 'writers', 'production_companies', 'production_countries'] {'genres_x': ['Action', 'Fantasy', 'Adventure', 'Sci-Fi', 'Music', 'Game-Show', '0', 'Biography', 'Horror', 'Film-Noir', 'Western', 'News', 'Musical', 'War', 'Drama', 'Documentary', 'Animation', 'History', 'Reality-TV', 'Short', 'Crime', 'Sport', 'Mystery', 'Missing', 'Talk-Show', 'Family', 'Thriller', 'Romance', 'Comedy', 'Adult'], 'titleType': ['tvSpecial', 'video', 'tvMiniSeries', 'tvShort', 'short', 'tvSeries', 'tvMovie', 'videoGame', 'tvEpisode', 'movie']} ['exp', 'runtimeMinutes', 'numVotes']\n",
      "creating parallel fitting job\n",
      "done\n",
      "done\n",
      "['directors', 'writers'] {'seasonNumber': 0, 'episodeNumber': 0, 'titleType': ['movie', None]}\n",
      "creating parallel fitting job\n",
      "done\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D96D3F60&gt;)),\n",
       "                                 (&#x27;runtimeTransform&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5189800&gt;)),\n",
       "                                 (&#x27;budgetTransform&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D51896C0&gt;)),\n",
       "                                 (&#x27;revenueTransform&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;funct...\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5188540&gt;)),\n",
       "                (&#x27;oneHotEncoder&#x27;,\n",
       "                 OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])),\n",
       "                (&#x27;get_all_companies&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C720&gt;)),\n",
       "                (&#x27;removeCategorical&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C860&gt;)),\n",
       "                (&#x27;removeExpColumn&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C7C0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D96D3F60&gt;)),\n",
       "                                 (&#x27;runtimeTransform&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5189800&gt;)),\n",
       "                                 (&#x27;budgetTransform&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D51896C0&gt;)),\n",
       "                                 (&#x27;revenueTransform&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;funct...\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5188540&gt;)),\n",
       "                (&#x27;oneHotEncoder&#x27;,\n",
       "                 OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])),\n",
       "                (&#x27;get_all_companies&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C720&gt;)),\n",
       "                (&#x27;removeCategorical&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C860&gt;)),\n",
       "                (&#x27;removeExpColumn&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C7C0&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;turnToNan&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D96D3F60&gt;)),\n",
       "                (&#x27;runtimeTransform&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5189800&gt;)),\n",
       "                (&#x27;budgetTransform&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D51896C0&gt;)),\n",
       "                (&#x27;revenueTransform&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5188F40&gt;)...\n",
       "                                               &#x27;tagline&#x27;, &#x27;video&#x27;])),\n",
       "                (&#x27;fill_nans&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5188E00&gt;)),\n",
       "                (&#x27;meanMedianImputer&#x27;,\n",
       "                 MeanMedianImputer(variables=[&#x27;runtimeMinutes&#x27;, &#x27;seasonNumber&#x27;,\n",
       "                                              &#x27;episodeNumber&#x27;, &#x27;ordering&#x27;,\n",
       "                                              &#x27;isOriginalTitle&#x27;, &#x27;popularity&#x27;,\n",
       "                                              &#x27;runtime&#x27;])),\n",
       "                (&#x27;getSTRsFromDicts&#x27;,\n",
       "                 TransformFromDict(variables=[&#x27;production_companies&#x27;,\n",
       "                                              &#x27;production_countries&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D96D3F60&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5189800&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D51896C0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5188F40&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5188EA0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer(variables=[&#x27;genres_x&#x27;, &#x27;language&#x27;, &#x27;attributes&#x27;, &#x27;adult&#x27;,\n",
       "                              &#x27;genres_y&#x27;, &#x27;original_language&#x27;,\n",
       "                              &#x27;production_companies&#x27;, &#x27;production_countries&#x27;,\n",
       "                              &#x27;status&#x27;, &#x27;tagline&#x27;, &#x27;video&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5188E00&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MeanMedianImputer</label><div class=\"sk-toggleable__content\"><pre>MeanMedianImputer(variables=[&#x27;runtimeMinutes&#x27;, &#x27;seasonNumber&#x27;, &#x27;episodeNumber&#x27;,\n",
       "                             &#x27;ordering&#x27;, &#x27;isOriginalTitle&#x27;, &#x27;popularity&#x27;,\n",
       "                             &#x27;runtime&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TransformFromDict</label><div class=\"sk-toggleable__content\"><pre>TransformFromDict(variables=[&#x27;production_companies&#x27;, &#x27;production_countries&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GetExpDict</label><div class=\"sk-toggleable__content\"><pre>GetExpDict(categories={&#x27;genres_x&#x27;: [&#x27;Action&#x27;, &#x27;Fantasy&#x27;, &#x27;Adventure&#x27;, &#x27;Sci-Fi&#x27;,\n",
       "                                    &#x27;Music&#x27;, &#x27;Game-Show&#x27;, &#x27;0&#x27;, &#x27;Biography&#x27;,\n",
       "                                    &#x27;Horror&#x27;, &#x27;Film-Noir&#x27;, &#x27;Western&#x27;, &#x27;News&#x27;,\n",
       "                                    &#x27;Musical&#x27;, &#x27;War&#x27;, &#x27;Drama&#x27;, &#x27;Documentary&#x27;,\n",
       "                                    &#x27;Animation&#x27;, &#x27;History&#x27;, &#x27;Reality-TV&#x27;,\n",
       "                                    &#x27;Short&#x27;, &#x27;Crime&#x27;, &#x27;Sport&#x27;, &#x27;Mystery&#x27;,\n",
       "                                    &#x27;Missing&#x27;, &#x27;Talk-Show&#x27;, &#x27;Family&#x27;,\n",
       "                                    &#x27;Thriller&#x27;, &#x27;Romance&#x27;, &#x27;Comedy&#x27;, &#x27;Adult&#x27;],\n",
       "                       &#x27;titleType&#x27;: [&#x27;tvSpecial&#x27;, &#x27;video&#x27;, &#x27;tvMiniSeries&#x27;,\n",
       "                                     &#x27;tvShort&#x27;, &#x27;short&#x27;, &#x27;tvSeries&#x27;, &#x27;tvMovie&#x27;,\n",
       "                                     &#x27;videoGame&#x27;, &#x27;tvEpisode&#x27;, &#x27;movie&#x27;]},\n",
       "           group=[&#x27;directors&#x27;, &#x27;writers&#x27;, &#x27;production_companies&#x27;,\n",
       "                  &#x27;production_countries&#x27;],\n",
       "           simple_only=[&#x27;production_companies&#x27;, &#x27;production_countries&#x27;],\n",
       "           simple_targets=[&#x27;runtimeMinutes&#x27;, &#x27;numVotes&#x27;],\n",
       "           targets=[&#x27;exp&#x27;, &#x27;runtimeMinutes&#x27;, &#x27;numVotes&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GetDetailedExp</label><div class=\"sk-toggleable__content\"><pre>GetDetailedExp(group=[&#x27;directors&#x27;, &#x27;writers&#x27;],\n",
       "               targets={&#x27;episodeNumber&#x27;: 0, &#x27;seasonNumber&#x27;: 0,\n",
       "                        &#x27;titleType&#x27;: [&#x27;movie&#x27;, None]})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function binarize_genres at 0x00000196D51884A0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D5188540&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(variables=[&#x27;titleType&#x27;, &#x27;status&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C720&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C860&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000196D3E7C7C0&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('turnToNan',\n",
       "                                  FunctionTransformer(func=<function <lambda> at 0x00000196D96D3F60>)),\n",
       "                                 ('runtimeTransform',\n",
       "                                  FunctionTransformer(func=<function <lambda> at 0x00000196D5189800>)),\n",
       "                                 ('budgetTransform',\n",
       "                                  FunctionTransformer(func=<function <lambda> at 0x00000196D51896C0>)),\n",
       "                                 ('revenueTransform',\n",
       "                                  FunctionTransformer(func=<funct...\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x00000196D5188540>)),\n",
       "                ('oneHotEncoder',\n",
       "                 OneHotEncoder(variables=['titleType', 'status'])),\n",
       "                ('get_all_companies',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x00000196D3E7C720>)),\n",
       "                ('removeCategorical',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x00000196D3E7C860>)),\n",
       "                ('removeExpColumn',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x00000196D3E7C7C0>))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X,y) #4m 30.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#X_pred = pd.read_csv('dataset/testear.csv').drop(['Unnamed: 0'],axis=1)\n",
    "jjjj = pipeline.transform(X)\n",
    "\n",
    "#293 3m 42.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" jjjj['averageRating'] = y\\njjjj.to_csv('dataset/transformedd.csv') \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding the target\n",
    "\"\"\" jjjj['averageRating'] = y\n",
    "jjjj.to_csv('dataset/transformedd.csv') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test2 = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "# import cupy as cp\n",
    "# import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a XGBRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training the XGBRegressor\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4465750333055214"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = XGBRegressor(n_estimators=1100,eta=0.05,\n",
    "                        max_depth=19,gamma = 0.20,\n",
    "                        colsample_bytree = 0.7,colsample_bylevel=0.7,colsample_bynode=0.8,\n",
    "                        tree_method = 'hist',\n",
    "                        max_cached_hist_node=262144) # type: ignore\n",
    "#regr = XGBRegressor(n_estimators=1200, eta=0.35, max_depth=7, multi_strategy=\"multi_output_tree\", min_child_weight=1, subsample=1, colsample_bytree=1, gamma=0, alpha=0)\n",
    "print(\"Training a XGBRegressor\")\n",
    "regr.fit(jjjj, y)\n",
    "print(\"Finished training the XGBRegressor\")\n",
    "#Tarda 49 minutos con esos settings 4565\n",
    "regr.score(pipeline.transform(X_test),y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lrerg = LGBMRegressor(n_estimators=5000,learning_rate=0.2)\n",
    "lrerg.fit(pipeline.transform(X), y)\n",
    "lrerg.score(pipeline.transform(X_test),y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [1000, 1500, 2000],\n",
    "    'max_depth': [6, 8, 10,17,19,20],\n",
    "    'gamma':[0.1,0.2,0.3,0.5,0.7,1],\n",
    "    'min_child_weight': [1,2,3,4],\n",
    "}\n",
    "\n",
    "regr = XGBRegressor()\n",
    "grid_search = RandomizedSearchCV(regr, param_grid,n_iter=100, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(jjjj, y)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\"\"\" \n",
    "regr.fit(jjjj, y)\n",
    "regr.score(X_test,y_test) #8 ~ 0.4165 # 5000 y 4 = 0.3958 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_test = pipeline.transform(X_test)\n",
    "print(\"Predicting\")\n",
    "score = regr.score(X_test, y_test) #4797\n",
    "\n",
    "print(f\"R^2 score on testing data: {score:.4f}\") \n",
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "#print(set(X_pred.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pd.read_csv('dataset/testear.csv').rename(columns={'Unnamed: 0':'exp'})\n",
    "\n",
    "X_pred = pipeline.transform(X_pred)\n",
    "Yest = regr.predict(X_pred).clip(1, 10)\n",
    "salida = pd.DataFrame(data={\"averageRating\": Yest})\n",
    "salida.index = X_pred.index\n",
    "salida.to_csv(\"predicciones/pred40.csv\", sep=',',index=True,  index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
