{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/AnalisisPredictivo/blob/master/Kaggle/2023Q2/Un_primer_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK-5cdUyNiQ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lineartree import LinearForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP11tcaGOEfg"
      },
      "outputs": [],
      "source": [
        "df_val=pd.read_csv('dataset/testear.csv')\n",
        "df_train=pd.read_csv('dataset/origen.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def give_authors_experience(writer):\n",
        "    authors = []\n",
        "    if type(writer) != str:\n",
        "        return authors\n",
        "    \n",
        "    for i,author in enumerate(writer.split(',')):\n",
        "        authors.append(writer_counts[author])\n",
        "    \n",
        "    return sum(authors)\n",
        "writers = df_train['writers']\n",
        "writers = writers.str.split(',', expand=True)\n",
        "writer_counts = writers.stack().value_counts()\n",
        "writer_counts['0'] = 0\n",
        "\n",
        "\n",
        "#apply the function to the writers column, send also the ratings column to the function\n",
        "df_train['writers_exp'] = df_train['writers'].apply(give_authors_experience)\n",
        "\n",
        "\n",
        "writers = df_val['writers']\n",
        "writers = writers.str.split(',', expand=True)\n",
        "writer_counts = writers.stack().value_counts()\n",
        "writer_counts['0'] = 0\n",
        "\n",
        "\n",
        "df_val['writers_exp'] = df_val['writers'].apply(give_authors_experience)\n",
        "#explode the writers column\n",
        "df_train = df_train.explode('writers')\n",
        "df_val = df_val.explode('writers')\n",
        "\n",
        "del writers, writer_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the writers column into separate writers\n",
        "writers = df_train['writers'].str.split(',', expand=True).stack()\n",
        "\n",
        "# Define a function to calculate the average rating for a writer\n",
        "def get_writer_rating(writer):\n",
        "    mask = df_train['writers'].str.split(',').apply(lambda x: writer in x)\n",
        "    mean_rating = df_train.loc[mask, 'averageRating'].mean()\n",
        "    print(print(writer, mean_rating))\n",
        "    return mean_rating\n",
        "\n",
        "# Calculate the average rating for each writer using the apply method\n",
        "writer_ratings = writers.drop_duplicates().apply(get_writer_rating).to_dict()\n",
        "\n",
        "# Add a default value of 0 for missing writers\n",
        "writer_ratings['0'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def give_writers_avg_rating(writer,ratings):\n",
        "    authors = []\n",
        "    if type(writer) != str:\n",
        "        return ratings[writer]\n",
        "    \n",
        "    for i,author in enumerate(writer.split(',')):\n",
        "        authors.append(ratings[author])\n",
        "    \n",
        "    return sum(authors)/len(authors)\n",
        "\n",
        "#apply the function to the writers column, send also the ratings column to the function\n",
        "\n",
        "df_train['writers_avg_rating'] = df_train['writers'].apply(give_writers_avg_rating, args=(writer_ratings,))\n",
        "\n",
        "writer_ratings = df_val.groupby('writers')['averageRating'].mean().to_dict()\n",
        "writer_ratings['0'] = 0 # probar si esto mejora el resultado\n",
        "\n",
        "df_val['writers_avg_rating'] = df_val['writers'].apply(give_writers_avg_rating,args=(writer_ratings,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2cfK0WTjylW"
      },
      "outputs": [],
      "source": [
        "y=df_train.averageRating\n",
        "vars=['startYear', 'runtimeMinutes',\"numVotes\",\"isAdult\",\"endYear\",\"writers_exp\"]\n",
        "X=df_train[vars]\n",
        "X_pred=df_val[vars]\n",
        "\n",
        "\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "\n",
        "title = encoder.fit_transform(df_train[['titleType']])\n",
        "title_df = pd.DataFrame(title.toarray(), columns=encoder.get_feature_names_out(['titleType']))\n",
        "#split by genres\n",
        "genres = df_train.genres_x.str.get_dummies(sep=',')\n",
        "genres = genres.reindex(sorted(genres.columns), axis=1)\n",
        "\n",
        "\n",
        "title_df = pd.concat([title_df, genres], axis=1)\n",
        "\n",
        "X = pd.concat([X, title_df], axis=1)\n",
        "\n",
        "title = encoder.fit_transform(df_val[['titleType']])\n",
        "title_df = pd.DataFrame(title.toarray(), columns=encoder.get_feature_names_out(['titleType']))\n",
        "genres = df_val.genres_x.str.get_dummies(sep=',')\n",
        "#sort the genres columns alphabetically\n",
        "genres = genres.reindex(sorted(genres.columns), axis=1)\n",
        "# Split the genres_x column by commas and expand into separate columns\n",
        "\n",
        "# Iterate over the columns in genres and add missing columns to X_pred\n",
        "\"\"\" for col in X.columns:\n",
        "    if col not in genres.columns:\n",
        "        genres[col] = 0 \"\"\"\n",
        "\n",
        "# Reorder the columns to match the order in X\n",
        "#genres = genres[X_pred.columns]\n",
        "\n",
        "# Concatenate the new genres DataFrame with X_pred\n",
        "title_df = pd.concat([title_df, genres], axis=1)\n",
        "X_pred = pd.concat([X_pred, title_df], axis=1)\n",
        "\n",
        "\n",
        "del title_df, genres, title, encoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "regr = LinearForestRegressor(base_estimator=LinearRegression(), max_features=0.5,n_estimators=75) # type: ignore\n",
        "print(\"Training a LinearForestRegressor with {} estimators\".format(regr.n_estimators))\n",
        "regr.fit(X_train, y_train)\n",
        "print(\"Finished training the LinearForestRegressor\")\n",
        "score = regr.score(X_test, y_test)\n",
        "print(\"R^2 score on testing data: {:.4f}\".format(score)) \n",
        "# 0.7 - 0.3819 | 0.6 - 0.3845 | 0.5 - 0.3867 | 0.4 - 0.3862\n",
        "# 50 - 0.3862 | 60 - 0.3875 | 70 - 0.3886 | 75 - 0.3888 | 80 - 0.3886\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Define the number of threads to use\n",
        "num_threads = 4\n",
        "\n",
        "# Define the random states to use\n",
        "random_states = [12, 21, 36, 42]\n",
        "\n",
        "# Define the training and testing data\n",
        "\n",
        "\n",
        "# Define a function to train the model and return the R^2 score\n",
        "def train_model(random_state):\n",
        "    # Create a LinearForestRegressor with the specified random state\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "    regr = LinearForestRegressor(base_estimator=LinearRegression(), max_features=0.5, n_estimators=75)\n",
        "    print(\"Training a LinearForestRegressor with {} estimators and random state {}\".format(regr.n_estimators, random_state))\n",
        "    regr.fit(X_train, y_train)\n",
        "    print(\"Finished training the LinearForestRegressor with random state {}\".format(random_state))\n",
        "    score = regr.score(X_test, y_test)\n",
        "    print(\"R^2 score on testing data with random state {}: {:.4f}\".format(random_state, score))\n",
        "    return score\n",
        "\n",
        "# Use a ThreadPoolExecutor to run the function on multiple threads\n",
        "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "    # Submit the function to the executor for each random state\n",
        "    futures = [executor.submit(train_model, random_state) for random_state in random_states]\n",
        "\n",
        "    # Wait for all the futures to complete and get the results\n",
        "    results = [future.result() for future in futures]\n",
        "\n",
        "# Print the average R^2 score across all the random states\n",
        "print(\"Average R^2 score across all random states: {:.4f}\".format(sum(results) / len(results)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assume regr is your trained LinearForestRegressor\n",
        "predictions = regr.predict(X_test)\n",
        "\n",
        "# Create a scatter plot of predicted vs actual values with transparency\n",
        "plt.scatter(y_test, predictions, alpha=0.1)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values')\n",
        "\n",
        "# Plot a line for perfect correlation. This serves as a reference line.\n",
        "plt.plot(y, y, 'r')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Yest = regr.predict(X_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Assume regr is your trained LinearForestRegressor\n",
        "importances = regr.feature_importances_\n",
        "\n",
        "# Convert to pandas Series for easier plotting\n",
        "importances = pd.Series(importances, index=X.columns)\n",
        "\n",
        "# Sort importances\n",
        "importances = importances.sort_values()\n",
        "\n",
        "# Plot\n",
        "importances.plot(kind='barh')\n",
        "plt.title('Feature Importances')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lineartree import RandomForestRegressor\n",
        "regr = RandomForestRegressor( max_features=0.5,n_estimators=75) # type: ignore\n",
        "print(\"Training a random forest with n estimators\")\n",
        "regr.fit(X_train, y_train)\n",
        "print(\"Finished training the LinearForestRegressor\")\n",
        "score = regr.score(X_test, y_test)\n",
        "print(\"R^2 score on testing data: {:.4f}\".format(score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3USDelPp-Df"
      },
      "outputs": [],
      "source": [
        "salida = pd.DataFrame(data={\"averageRating\": Yest})\n",
        "salida.index = df_val.index\n",
        "salida.to_csv(\"pred3.csv\", sep=',',index=True,  index_label='Id')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWrEHZs9zDfmtIg+jWBoNC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
