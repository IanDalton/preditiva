{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/AnalisisPredictivo/blob/master/Kaggle/2023Q2/Un_primer_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uK-5cdUyNiQ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import json,re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from preparando_datos import sum_into_column,split_and_sum\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DP11tcaGOEfg"
      },
      "outputs": [],
      "source": [
        "df_val=pd.read_csv('dataset/testear.csv')\n",
        "df_train=pd.read_csv('dataset/origen.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasons worked\n",
        "for df in [df_train,df_val]:\n",
        "    writers = df.groupby(\"directors\").count()[\"Unnamed: 0\"].to_dict()\n",
        "    writers = split_and_sum(writers)\n",
        "    df[\"directors_exp\"] = df[\"directors\"].apply(sum_into_column,args=(writers,))\n",
        "    \n",
        "for df in [df_val,df_train]:\n",
        "    seasons = df.groupby(\"directors\").count()[\"seasonNumber\"].to_dict()\n",
        "    seasons = split_and_sum(seasons)\n",
        "    df[\"dir_seasonsOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(seasons,))\n",
        "\n",
        "# episodes worked\n",
        "for df in [df_val,df_train]:\n",
        "    episodes = df.groupby(\"directors\").count()[\"episodeNumber\"].to_dict()\n",
        "    episodes = split_and_sum(episodes)\n",
        "    df[\"dir_episodesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(episodes,))\n",
        "    \n",
        "# movies worked\n",
        "for df in [df_val,df_train]:\n",
        "    movies = df[df[\"titleType\"] == \"movie\"].groupby(\"directors\").count()[\"titleType\"].to_dict()\n",
        "    movies = split_and_sum(movies)\n",
        "    df[\"dir_moviesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "# other xp than movies\n",
        "for df in [df_val,df_train]:\n",
        "    others = df[df[\"titleType\"] != \"movie\"].groupby(\"directors\").count()[\"titleType\"].to_dict()\n",
        "    others = split_and_sum(others)\n",
        "    df[\"dir_othersOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "del seasons,episodes,movies,others,df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in [df_train,df_val]:\n",
        "    writers = df.groupby(\"writers\").count()[\"Unnamed: 0\"].to_dict()\n",
        "    writers = split_and_sum(writers)\n",
        "    df[\"writers_exp\"] = df[\"writers\"].apply(sum_into_column,args=(writers,))\n",
        "\n",
        "for df in [df_val,df_train]:\n",
        "    seasons = df.groupby(\"writers\").count()[\"seasonNumber\"].to_dict()\n",
        "    seasons = split_and_sum(seasons)\n",
        "    df[\"writer_seasonsOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(seasons,))\n",
        "\n",
        "for df in [df_val,df_train]:\n",
        "    episodes = df.groupby(\"writers\").count()[\"episodeNumber\"].to_dict()\n",
        "    episodes = split_and_sum(episodes)\n",
        "    df[\"writer_episodesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(episodes,))\n",
        "\n",
        "for df in [df_val,df_train]:\n",
        "    movies = df[df[\"titleType\"] == \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "    movies = split_and_sum(movies)\n",
        "    df[\"writer_moviesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "for df in [df_val,df_train]:\n",
        "    others = df[df[\"titleType\"] != \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "    others = split_and_sum(others)\n",
        "    df[\"writer_othersOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "del seasons,episodes,movies,others,df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'Minerva Film SpA', 'id': 153}, {'name': 'Rieti Film', 'id': 12136}]\n",
            "[{'name\": 'Minerva Film SpA\", 'id\": 153}, {'name\": 'Rieti Film\", 'id\": 12136}]\n",
            "[{'name\": 'Minerva Film SpA\", 'id\": 153}, {'name\": 'Rieti Film\", 'id\": 12136}]\n"
          ]
        },
        {
          "ename": "JSONDecodeError",
          "evalue": "Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32ms:\\Github\\preditiva\\preparando_dataset.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39;49mloads(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError:\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32ms:\\Github\\preditiva\\preparando_dataset.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mproduction_companies\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mproduction_companies\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfillna(\u001b[39m\"\u001b[39m\u001b[39m[]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#turn str list into list\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mproduction_companies\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mproduction_companies\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(parse_json)\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32ms:\\Github\\preditiva\\preparando_dataset.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/Github/preditiva/preparando_dataset.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39;49mloads(x)\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
            "File \u001b[1;32mc:\\Users\\ianda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)"
          ]
        }
      ],
      "source": [
        "def parse_json(x):\n",
        "    try:\n",
        "        return json.loads(x)\n",
        "    except json.JSONDecodeError:\n",
        "        print(x)\n",
        "        pattern = r\"^'|(\\w)'(\\w*[,:])\"\n",
        "        replacement = r'\\1\"\\2'\n",
        "        x = re.sub(pattern, replacement, x)\n",
        "        print(x)\n",
        "        \n",
        "        \n",
        "        print(x)\n",
        "        return json.loads(x)\n",
        "for df in [df_train]:\n",
        "    #turn production company into a list\n",
        "    #fill nans with empty list\n",
        "    df[\"production_companies\"] = df[\"production_companies\"].fillna(\"[]\")\n",
        "    #turn str list into list\n",
        "    df[\"production_companies\"] = df[\"production_companies\"].apply(parse_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# turn video colunm into 1 or 0\n",
        "# video column might have False, True or NaN values\n",
        "for df in [df_val,df_train]:\n",
        "    df[\"video\"] = df[\"video\"].fillna(False)\n",
        "    df[\"video\"] = df[\"video\"].astype(int)\n",
        "\n",
        "# turn tagline into the lenth of the tagline\n",
        "for df in [df_val,df_train]:\n",
        "    df[\"tagline\"] = df[\"tagline\"].fillna(\"\")\n",
        "    df[\"tagline\"] = df[\"tagline\"].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set language to 0 if it is nan\n",
        "\n",
        "df_train['language'] = df_train['language'].fillna(0)\n",
        "df_val['language'] = df_val['language'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "y=df_train.averageRating\n",
        "vars=['startYear', 'runtimeMinutes',\"numVotes\",\"writers_exp\",\n",
        "      \"directors_exp\",\"endYear\",\"isAdult\",\"seasonNumber\",\n",
        "      \"episodeNumber\",\"ordering\",\"isOriginalTitle\",\"runtime\",\n",
        "      \"revenue\",\"popularity\",\"budget\",\"dir_seasonsOfExperience\",\n",
        "      \"dir_episodesOfExperience\",\"dir_othersOfExperience\",\"dir_moviesOfExperience\",\n",
        "      \"writer_seasonsOfExperience\",\"writer_episodesOfExperience\",\"writer_othersOfExperience\",\n",
        "      \"writer_moviesOfExperience\",\"video\",\"tagline\"]\n",
        "X=df_train[vars]\n",
        "X = pd.concat([X, pd.get_dummies(df_train['language'], prefix='language')], axis=1)\n",
        "X = pd.concat([X, pd.get_dummies(df_train['status'], prefix='status')], axis=1)\n",
        "X_pred=df_val[vars]\n",
        "X_pred = pd.concat([X_pred, pd.get_dummies(df_val['language'], prefix='language')], axis=1)\n",
        "X_pred = pd.concat([X_pred, pd.get_dummies(df_val['status'], prefix='status')], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "K2cfK0WTjylW"
      },
      "outputs": [],
      "source": [
        "for i,df in enumerate([df_train, df_val]):\n",
        "    encoder = OneHotEncoder()\n",
        "    title = encoder.fit_transform(df[['titleType']])\n",
        "    title_df = pd.DataFrame(title.toarray(), columns=encoder.get_feature_names_out(['titleType']))\n",
        "    #split by genres\n",
        "    genres = df.genres_x.str.get_dummies(sep=',')\n",
        "    genres = genres.reindex(sorted(genres.columns), axis=1)\n",
        "\n",
        "\n",
        "    title_df = pd.concat([title_df, genres], axis=1)\n",
        "    if not i:\n",
        "        X = pd.concat([X, title_df], axis=1)\n",
        "    else:\n",
        "        X_pred = pd.concat([X_pred, title_df], axis=1)\n",
        "\n",
        "\n",
        "for col in X.columns:\n",
        "    if col not in X_pred.columns:\n",
        "        X_pred[col] = 0\n",
        "\n",
        "\n",
        "del title_df, genres, title, encoder, df\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['0', 'Action', 'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy',\n",
            "       'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir',\n",
            "       'Game-Show', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News',\n",
            "       'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Talk-Show',\n",
            "       'Thriller', 'War', 'Western', 'budget', 'dir_episodesOfExperience',\n",
            "       'dir_moviesOfExperience', 'dir_othersOfExperience',\n",
            "       'dir_seasonsOfExperience', 'directors_exp', 'endYear', 'episodeNumber',\n",
            "       'isAdult', 'isOriginalTitle', 'language_0', 'language_en',\n",
            "       'language_es', 'language_fr', 'language_haw', 'language_hi',\n",
            "       'language_myv', 'language_yi', 'numVotes', 'ordering', 'popularity',\n",
            "       'revenue', 'runtime', 'runtimeMinutes', 'seasonNumber', 'startYear',\n",
            "       'status_In Production', 'status_Planned', 'status_Post Production',\n",
            "       'status_Released', 'status_Rumored', 'tagline', 'titleType_movie',\n",
            "       'titleType_short', 'titleType_tvEpisode', 'titleType_tvMiniSeries',\n",
            "       'titleType_tvMovie', 'titleType_tvSeries', 'titleType_tvShort',\n",
            "       'titleType_tvSpecial', 'titleType_video', 'titleType_videoGame',\n",
            "       'video', 'writer_episodesOfExperience', 'writer_moviesOfExperience',\n",
            "       'writer_othersOfExperience', 'writer_seasonsOfExperience',\n",
            "       'writers_exp'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#drop duplicate columns\n",
        "X = X.loc[:,~X.columns.duplicated()]\n",
        "X_pred = X_pred.loc[:,~X_pred.columns.duplicated()]\n",
        "print(X.columns)\n",
        "#add missing columns\n",
        "for col in X.columns:\n",
        "    if col not in X_pred.columns:\n",
        "        X_pred[col] = 0\n",
        "for col in X_pred.columns:\n",
        "    if col not in X.columns:\n",
        "        X[col] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_pred = X_pred.sort_index(axis=1)\n",
        "X = X.sort_index(axis=1)\n",
        "X.to_csv('dataset/train.csv', index=False)\n",
        "X_pred.to_csv('dataset/val.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWrEHZs9zDfmtIg+jWBoNC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
