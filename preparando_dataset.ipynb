{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/AnalisisPredictivo/blob/master/Kaggle/2023Q2/Un_primer_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uK-5cdUyNiQ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import json,re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from preparando_datos import sum_into_column,split_and_sum,get_min_max\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DP11tcaGOEfg"
      },
      "outputs": [],
      "source": [
        "df_val=pd.read_csv('dataset/testear.csv')\n",
        "df_train=pd.read_csv('dataset/origen.csv')\n",
        "#split the train dataset into train and test\n",
        "#df_train, df_test = train_test_split(df_train, test_size=0.1, random_state=421)\n",
        "\n",
        "df_list = [df_train,df_val]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import AddMissingIndicator, CategoricalImputer, MeanMedianImputer\n",
        "for df in df_list:\n",
        "    #turn numVotes into int\n",
        "    df['numVotes'] = df['numVotes'].astype(int)\n",
        "    df[\"dir_qty\"] = pd.Series(df[\"directors\"]).str.split(\",\").apply(len)\n",
        "    df[\"writers_qty\"] = pd.Series(df[\"writers\"]).str.split(\",\").apply(len)\n",
        "    \n",
        "df_train = pd.DataFrame(AddMissingIndicator(variables=['seasonNumber','episodeNumber','language','runtimeMinutes',\"genres_x\",'status','tagline','video']).fit_transform(df_train))\n",
        "df_val = pd.DataFrame(AddMissingIndicator(variables=['seasonNumber','episodeNumber','language','runtimeMinutes',\"genres_x\",'status','tagline','video']).fit_transform(df_val))\n",
        "df_list = [df_train,df_val]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "runtimeMean = df_train['runtimeMinutes'].quantile(0.5)\n",
        "budgetMean = df_train['budget'].quantile(0.5)\n",
        "revenueMean = df_train['revenue'].quantile(0.5)\n",
        "votesMean = df_train['numVotes'].quantile(0.5)\n",
        "#Get over the 3 quantile\n",
        "runtimeQ3 = df_train['runtimeMinutes'].quantile(0.75)\t\n",
        "budgetQ3 = df_train['budget'].quantile(0.75)\n",
        "revenueQ3 = df_train['revenue'].quantile(0.75)\n",
        "votesQ3 = df_train['numVotes'].quantile(0.75)\n",
        "dirMean = df_train['dir_qty'].quantile(0.5)\n",
        "dirQ3 = df_train['dir_qty'].quantile(0.75)\n",
        "writerMean = df_train['writers_qty'].quantile(0.5)\n",
        "writerQ3 = df_train['writers_qty'].quantile(0.75)\n",
        "\n",
        "\n",
        "\n",
        "for df in df_list:\n",
        "    # flag if the value is over the mean\n",
        "    df['runtimeMinutes_over_mean'] = np.where(df['runtimeMinutes']>runtimeMean, np.where(df['runtimeMinutes']>runtimeQ3,2,1), 0)\n",
        "    df['budget_over_mean'] = np.where(df['budget']>budgetMean,np.where(df['budget']>budgetQ3,2,1), 0)\n",
        "    df['revenue_over_mean'] = np.where(df['revenue']> revenueMean,np.where(df['revenue']>revenueQ3,2,1),0)\n",
        "    df['numVotes_over_mean'] = np.where(df['numVotes']> votesMean,np.where(df['numVotes']>votesQ3,2,1),0)\n",
        "    df['dir_qty_over_mean'] = np.where(df['dir_qty']> dirMean,np.where(df['dir_qty']>dirQ3,2,1),0)\n",
        "    df['writers_qty_over_mean'] = np.where(df['writers_qty']> writerMean,np.where(df['writers_qty']>writerQ3,2,1),0)\n",
        "\n",
        "del runtimeMean,budgetMean,revenueMean,votesMean,runtimeQ3,budgetQ3,revenueQ3,votesQ3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for df in df_list:\n",
        "    # if isAdult is larger than 1, then set it to 1, if smaller that 0, then set it to 0\n",
        "    df['isAdult'] = df['isAdult'].apply(lambda x: 1 if x > 1 else x)\n",
        "    df['seasonNumber'] = df['seasonNumber'].fillna(0)\n",
        "    df['episodeNumber'] = df['episodeNumber'].fillna(1)\n",
        "    df['ordering'] = df['ordering'].fillna(0)\n",
        "    df['language'] = df['language'].fillna(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ADAPTADO A PIPELINE\n",
        "# Completando los 0 con los promedios tomando en cuenta si son series, peliculas o episodios\n",
        "\n",
        "for df in df_list:\n",
        "    \n",
        "    df['runtimeMinutes'] = df['runtimeMinutes'].replace(0, np.nan)\n",
        "    df['runtimeMinutes'] = df.groupby('titleType')['runtimeMinutes'].apply(lambda x: x.interpolate(method='linear')).reset_index(level=0, drop=True)\n",
        "    \n",
        "    #Lo mismo pero para el budget\n",
        "    df['budget'] = df['budget'].replace(0, np.nan)\n",
        "    df['budget'] = df.groupby('titleType')['budget'].apply(lambda x: x.interpolate(method='linear')).reset_index(level=0, drop=True)\n",
        "    \n",
        "    # Si endYear es 0, entonces se le asigna el valor de startYear\n",
        "    df['endYear'] = df.apply(lambda x: x['startYear'] if x['endYear'] == 0 else x['endYear'], axis=1)\n",
        "\n",
        "    # Lo mismo pero para revenue\n",
        "    df['revenue'] = df['revenue'].replace(0, np.nan)\n",
        "    df['revenue'] = df.groupby('titleType')['revenue'].apply(lambda x: x.interpolate(method='linear')).reset_index(level=0, drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\4185133187.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "#ADAPTADO A PIPELINE\n",
        "def get_exp_dict(df:pd.DataFrame,group:str,categories:str):\n",
        "    categorias = df[categories].unique().tolist()\n",
        "    categorias = [x.split(',') if type(x) == str else [] for x in categorias]\n",
        "    categorias = [item for sublist in categorias for item in sublist]\n",
        "    categorias = list(set(categorias))\n",
        "\n",
        "    grupo = df.groupby(group)[categories].apply(list).to_dict()\n",
        "    if '0' in grupo:\n",
        "        del grupo['0']\n",
        "    \n",
        "    dict_limpio = dict()\n",
        "    for director in grupo.keys():\n",
        "        shows = grupo[director]\n",
        "        \n",
        "        for dir in director.split(','):\n",
        "            if dir in dict_limpio:\n",
        "                dict_limpio[dir] += shows\n",
        "            else:\n",
        "                dict_limpio[dir] = shows\n",
        "    for director in dict_limpio.keys():\n",
        "        #split all the genres into a list\n",
        "        dict_limpio[director] = [x.split(',') if type(x) == str else [] for x in dict_limpio[director]]\n",
        "        #flatten the list\n",
        "        dict_limpio[director] = [item for sublist in dict_limpio[director] for item in sublist]\n",
        "        #turn the list into a dict and count the number of times each genre appears\n",
        "        dict_limpio[director] = dict((x,dict_limpio[director].count(x)) for x in set(dict_limpio[director]))\n",
        "        # if not all genres are present, add the missing ones and set the count to 0\n",
        "        for cat in categorias:\n",
        "            if cat not in dict_limpio[director]:\n",
        "                dict_limpio[director][cat] = 0\n",
        "    return dict_limpio,categorias\n",
        "\n",
        "\n",
        "def set_exp_by_cat(df:pd.DataFrame,group:str,dict_limpio:dict,categorias:list,tipo:str):\n",
        "    for cat in categorias:\n",
        "        df[f'{group}_exp_{cat}_{tipo}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
        "    print('Done')\n",
        "\n",
        "dirs_exp_genres,genres = get_exp_dict(df_train,'directors','genres_x')\n",
        "writers_exp_genres,genres = get_exp_dict(df_train,'writers','genres_x')\n",
        "dirs_exp_titleType,titleType = get_exp_dict(df_train,'directors','titleType')\n",
        "writers_exp_titleType,titleType = get_exp_dict(df_train,'writers','titleType')\n",
        "\n",
        "for df in df_list:\n",
        "    set_exp_by_cat(df,'genres_x',dirs_exp_genres,genres,'dirs')\n",
        "    set_exp_by_cat(df,'genres_x',writers_exp_genres,genres,'writers')\n",
        "    set_exp_by_cat(df,'titleType',dirs_exp_titleType,titleType,'dirs')\n",
        "    set_exp_by_cat(df,'titleType',writers_exp_titleType,titleType,'writers')\n",
        "    \n",
        "del dirs_exp_genres,writers_exp_genres,dirs_exp_titleType,writers_exp_titleType,genres,titleType\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"directors_exp\"] = df[\"directors\"].apply(sum_into_column,args=(writers,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_minExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,0,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_maxExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,1,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_seasonsOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(seasons,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_episodesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(episodes,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_moviesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(movies,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_othersOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(others,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"directors_exp\"] = df[\"directors\"].apply(sum_into_column,args=(writers,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_minExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,0,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_maxExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,1,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_seasonsOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(seasons,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_episodesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(episodes,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_moviesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(movies,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\169548390.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_othersOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(others,))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Seasons worked\n",
        "\n",
        "writers = df_train.groupby(\"writers\").count()[\"Unnamed: 0\"].to_dict()\n",
        "writers = split_and_sum(writers)\n",
        "seasons = df_train.groupby(\"writers\").count()[\"seasonNumber\"].to_dict()\n",
        "seasons = split_and_sum(seasons)\n",
        "episodes = df_train.groupby(\"writers\").count()[\"episodeNumber\"].to_dict()\n",
        "episodes = split_and_sum(episodes)\n",
        "movies = df_train[df_train[\"titleType\"] == \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "movies = split_and_sum(movies)\n",
        "others = df_train[df_train[\"titleType\"] != \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "others = split_and_sum(others)\n",
        "\n",
        "for df in df_list:\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    df[\"directors_exp\"] = df[\"directors\"].apply(sum_into_column,args=(writers,))\n",
        "\n",
        "    df[\"dir_minExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,0,))\n",
        "\n",
        "    df[\"dir_maxExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,1,))\n",
        "\n",
        "    df[\"dir_seasonsOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(seasons,))\n",
        "\n",
        "\n",
        "    df[\"dir_episodesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(episodes,))\n",
        "\n",
        "\n",
        "    df[\"dir_moviesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "    df[\"dir_othersOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "del writers,seasons,episodes,movies,others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writers_exp\"] = df[\"writers\"].apply(sum_into_column,args=(writers_exp,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_minExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers_exp,0,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_maxExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers_exp,1,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_seasonsOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(seasons,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_episodesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(episodes,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_moviesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(movies,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_othersOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(others,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writers_exp\"] = df[\"writers\"].apply(sum_into_column,args=(writers_exp,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_minExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers_exp,0,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_maxExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers_exp,1,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_seasonsOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(seasons,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_episodesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(episodes,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_moviesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(movies,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\2747713769.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"writer_othersOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(others,))\n"
          ]
        }
      ],
      "source": [
        "writers_exp = df_train.groupby(\"writers\").count()[\"Unnamed: 0\"].to_dict()\n",
        "writers_exp = split_and_sum(writers_exp)\n",
        "seasons = df_train.groupby(\"writers\").count()[\"seasonNumber\"].to_dict()\n",
        "seasons = split_and_sum(seasons)\n",
        "episodes = df_train.groupby(\"writers\").count()[\"episodeNumber\"].to_dict()\n",
        "episodes = split_and_sum(episodes)\n",
        "movies = df_train[df_train[\"titleType\"] == \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "movies = split_and_sum(movies)\n",
        "others = df_train[df_train[\"titleType\"] != \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "others = split_and_sum(others)\n",
        "\n",
        "\n",
        "for df in df_list:\n",
        "\n",
        "\n",
        "    df[\"writers_exp\"] = df[\"writers\"].apply(sum_into_column,args=(writers_exp,))\n",
        "\n",
        "    df[\"writer_minExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers_exp,0,))\n",
        "\n",
        "    df[\"writer_maxExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers_exp,1,))\n",
        "\n",
        "    df[\"writer_seasonsOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(seasons,))\n",
        "    \n",
        "    df[\"writer_episodesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(episodes,))\n",
        "\n",
        "    df[\"writer_moviesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "    df[\"writer_othersOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "\n",
        "del seasons,episodes,movies,others,writers_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\3410312861.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"production_countries_experience\"] = df[\"production_countries\"].apply(sum_into_column,args=(experience,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\3410312861.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"production_companies_experience\"] = df[\"production_companies\"].apply(sum_into_column,args=(companies_experience,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\3410312861.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_votes\"] = df[\"directors\"].apply(sum_into_column,args=(dir_votes,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\3410312861.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"production_countries_experience\"] = df[\"production_countries\"].apply(sum_into_column,args=(experience,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\3410312861.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"production_companies_experience\"] = df[\"production_companies\"].apply(sum_into_column,args=(companies_experience,))\n",
            "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_14396\\3410312861.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"dir_votes\"] = df[\"directors\"].apply(sum_into_column,args=(dir_votes,))\n"
          ]
        }
      ],
      "source": [
        "def parse_json(x):\n",
        "    x = x.split(\":\")\n",
        "    x = x[1:]\n",
        "    for i in range(len(x)):\n",
        "        x[i] = x[i].split(\"}\")[0]\n",
        "        x[i] = x[i].split(\",\")[0]\n",
        "    \n",
        "    #split the list into pairs of two\n",
        "    x = [x[i:i+2] for i in range(0,len(x),2)]\n",
        "    # grab the first element of the pair\n",
        "    x = [i[0] for i in x]\n",
        "    #remove the quotes\n",
        "    x = [i.replace(\"'\",'') for i in x]\n",
        "    #remove the spaces\n",
        "    x = [i.strip() for i in x]\n",
        "\n",
        "    return \",\".join(x)\n",
        "\n",
        "for df in df_list:\n",
        "    df[\"production_countries\"] = df[\"production_countries\"].fillna(\"[]\")\n",
        "    #turn str list into list\n",
        "    df[\"production_countries\"] = df[\"production_countries\"].apply(parse_json)\n",
        "\n",
        "    df[\"production_companies\"] = df[\"production_companies\"].fillna(\"[]\")\n",
        "    #turn str list into list\n",
        "    df[\"production_companies\"] = df[\"production_companies\"].apply(parse_json)\n",
        "\n",
        "experience = df_train.groupby(\"genres_x\").count()[\"Unnamed: 0\"].to_dict()\n",
        "experience['']=0\n",
        "\n",
        "companies_experience = split_and_sum(df.groupby(\"production_companies\").count()[\"Unnamed: 0\"].to_dict())\n",
        "companies_experience['']=0\n",
        "\n",
        "dir_votes = df_train.groupby(\"directors\")[\"numVotes\"].sum().to_dict()\n",
        "dir_votes = split_and_sum(dir_votes)\n",
        "\n",
        "for df in df_list:\n",
        "\n",
        "    df[\"production_countries_experience\"] = df[\"production_countries\"].apply(sum_into_column,args=(experience,))\n",
        "\n",
        "    df['production_countries'] = df['production_countries'].apply(lambda x: len(x.split(',')))\n",
        "\n",
        "    #turn production company into a list\n",
        "    #fill nans with empty list\n",
        "\n",
        "\n",
        "    df[\"production_companies_experience\"] = df[\"production_companies\"].apply(sum_into_column,args=(companies_experience,))\n",
        "\n",
        "    df['production_companies'] = df['production_companies'].apply(lambda x: len(x.split(',')))\n",
        "    \n",
        "    df[\"dir_votes\"] = df[\"directors\"].apply(sum_into_column,args=(dir_votes,))\n",
        "    \n",
        "del experience,companies_experience,dir_votes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# turn video colunm into 1 or 0\n",
        "# video column might have False, True or NaN values\n",
        "for df in df_list:\n",
        "    df[\"video\"] = df[\"video\"].fillna(False)\n",
        "    df[\"video\"] = df[\"video\"].astype(int)\n",
        "    df[\"tagline\"] = df[\"tagline\"].fillna(\"\")\n",
        "    df[\"tagline\"] = df[\"tagline\"].apply(len)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "y=df_train.averageRating\n",
        "vars=['Unnamed: 0',  'titleType',\n",
        "       'genres_x', 'directors',\n",
        "       'writers','language',\n",
        "       'attributes', 'genres_y',\n",
        "        'production_companies',\n",
        "       'production_countries', 'adult',\n",
        "       'original_language', 'runtime', 'status']\n",
        "\n",
        "\n",
        "         # 'revenue' Evaluar si sirve o no\n",
        "       \n",
        "       \n",
        "X_pred = df_val.drop(columns= vars)\n",
        "X = df_train.drop(columns= vars)\n",
        "#X_test=df_test[vars]\n",
        "\n",
        "for db in [[X,df_train],[X_pred,df_val]]:\n",
        "      db[0] = pd.concat([db[0], pd.get_dummies(db[1]['language'], prefix='language')], axis=1)\n",
        "      db[0] = pd.concat([db[0], pd.get_dummies(db[1]['status'], prefix='status')], axis=1)\n",
        "\n",
        "del db\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "K2cfK0WTjylW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Done!\n",
            "1 Done!\n"
          ]
        }
      ],
      "source": [
        "for i,df in enumerate(df_list):\n",
        "    encoder = OneHotEncoder()\n",
        "    title = encoder.fit_transform(df[['titleType']])\n",
        "    title_df = pd.DataFrame(title.toarray(), columns=encoder.get_feature_names_out(['titleType']))\n",
        "    #split by genres\n",
        "    genres = df.genres_x.str.get_dummies(sep=',')\n",
        "    genres = genres.reindex(sorted(genres.columns), axis=1)\n",
        "\n",
        "    title_df = pd.concat([title_df, genres], axis=1)\n",
        "    if i==0:\n",
        "        X = pd.concat([X, title_df], axis=1)\n",
        "    elif i==1:\n",
        "        X_pred = pd.concat([X_pred, title_df], axis=1)\n",
        "    print(i,\"Done!\")\n",
        "    \n",
        "\n",
        "\n",
        "del title_df, genres, title, encoder, df,i\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "#Drop categorical columns but print them first\n",
        "for df in [X,X_pred]:\n",
        "    print(df.select_dtypes(include=['object']).columns.tolist())\n",
        "    df.drop(columns=df.select_dtypes(include=['object']).columns.tolist(),inplace=True)\n",
        "\n",
        "# Drop duplicate columns\n",
        "X = X.loc[:, ~X.columns.duplicated()]\n",
        "X_pred = X_pred.loc[:, ~X_pred.columns.duplicated()]\n",
        "\n",
        "\n",
        "# Add missing columns to X_pred and X_test\n",
        "missing_cols = set(X.columns) - set(X_pred.columns)\n",
        "X_pred = X_pred.reindex(columns=X_pred.columns.tolist() + list(missing_cols))\n",
        "\n",
        "\n",
        "# Add missing columns to X\n",
        "missing_cols = set(X_pred.columns) - set(X.columns)\n",
        "X = X.reindex(columns=X.columns.tolist() + list(missing_cols))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_pred = X_pred.sort_index(axis=1)\n",
        "X = X.sort_index(axis=1)\n",
        "\n",
        "\n",
        "#Drop averageRating from X_pred\n",
        "X_pred = X_pred.drop(columns=[\"averageRating\"])\n",
        "\n",
        "X.to_csv('dataset/train.csv', index=False)\n",
        "X_pred.to_csv('dataset/val.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWrEHZs9zDfmtIg+jWBoNC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
