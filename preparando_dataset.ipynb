{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/AnalisisPredictivo/blob/master/Kaggle/2023Q2/Un_primer_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uK-5cdUyNiQ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import json,re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from preparando_datos import sum_into_column,split_and_sum,get_min_max\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DP11tcaGOEfg"
      },
      "outputs": [],
      "source": [
        "df_val=pd.read_csv('dataset/testear.csv')\n",
        "df_train=pd.read_csv('dataset/origen.csv')\n",
        "#split the train dataset into train and test\n",
        "#df_train, df_test = train_test_split(df_train, test_size=0.1, random_state=421)\n",
        "\n",
        "df_list = [df_train,df_val]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in df_list:\n",
        "    # if isAdult is larger than 1, then set it to 1, if smaller that 0, then set it to 0\n",
        "    df['isAdult'] = df['isAdult'].apply(lambda x: 1 if x > 1 else x)\n",
        "    df['seasonNumber'] = df['seasonNumber'].fillna(0)\n",
        "    df['episodeNumber'] = df['episodeNumber'].fillna(1)\n",
        "    df['ordering'] = df['ordering'].fillna(0)\n",
        "    df['language'] = df['language'].fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ianda\\AppData\\Local\\Temp\\ipykernel_31308\\3645156677.py:4: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df['runtimeMinutes'] = df.groupby('titleType')['runtimeMinutes'].apply(lambda x: x.interpolate(method='linear'))\n",
            "C:\\Users\\ianda\\AppData\\Local\\Temp\\ipykernel_31308\\3645156677.py:8: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df['budget'] = df.groupby('titleType')['budget'].apply(lambda x: x.interpolate(method='linear'))\n",
            "C:\\Users\\ianda\\AppData\\Local\\Temp\\ipykernel_31308\\3645156677.py:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df['revenue'] = df.groupby('titleType')['revenue'].apply(lambda x: x.interpolate(method='linear'))\n",
            "C:\\Users\\ianda\\AppData\\Local\\Temp\\ipykernel_31308\\3645156677.py:4: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df['runtimeMinutes'] = df.groupby('titleType')['runtimeMinutes'].apply(lambda x: x.interpolate(method='linear'))\n",
            "C:\\Users\\ianda\\AppData\\Local\\Temp\\ipykernel_31308\\3645156677.py:8: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df['budget'] = df.groupby('titleType')['budget'].apply(lambda x: x.interpolate(method='linear'))\n",
            "C:\\Users\\ianda\\AppData\\Local\\Temp\\ipykernel_31308\\3645156677.py:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df['revenue'] = df.groupby('titleType')['revenue'].apply(lambda x: x.interpolate(method='linear'))\n"
          ]
        }
      ],
      "source": [
        "# Completando los 0 con los promedios tomando en cuenta si son series, peliculas o episodios\n",
        "for df in df_list:\n",
        "    df['runtimeMinutes'] = df['runtimeMinutes'].replace(0, np.nan)\n",
        "    df['runtimeMinutes'] = df.groupby('titleType')['runtimeMinutes'].apply(lambda x: x.interpolate(method='linear'))\n",
        "\n",
        "    #Lo mismo pero para el budget\n",
        "    df['budget'] = df['budget'].replace(0, np.nan)\n",
        "    df['budget'] = df.groupby('titleType')['budget'].apply(lambda x: x.interpolate(method='linear'))\n",
        "    \n",
        "    # Si endYear es 0, entonces se le asigna el valor de startYear\n",
        "    df['endYear'] = df.apply(lambda x: x['startYear'] if x['endYear'] == 0 else x['endYear'], axis=1)\n",
        "\n",
        "    # Lo mismo pero para revenue\n",
        "    df['revenue'] = df['revenue'].replace(0, np.nan)\n",
        "    df['revenue'] = df.groupby('titleType')['revenue'].apply(lambda x: x.interpolate(method='linear'))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasons worked\n",
        "\n",
        "for df in df_list:\n",
        "    \n",
        "    df[\"dir_qty\"] = pd.Series(df[\"directors\"]).str.split(\",\").apply(len)\n",
        "\n",
        "    writers = df.groupby(\"directors\").count()[\"Unnamed: 0\"].to_dict()\n",
        "    writers = split_and_sum(writers)\n",
        "    df[\"directors_exp\"] = df[\"directors\"].apply(sum_into_column,args=(writers,))\n",
        "\n",
        "    df[\"dir_minExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,0,))\n",
        "\n",
        "    df[\"dir_maxExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,1,))\n",
        "\n",
        "    seasons = df.groupby(\"directors\").count()[\"seasonNumber\"].to_dict()\n",
        "    seasons = split_and_sum(seasons)\n",
        "    df[\"dir_seasonsOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(seasons,))\n",
        "\n",
        "    episodes = df.groupby(\"directors\").count()[\"episodeNumber\"].to_dict()\n",
        "    episodes = split_and_sum(episodes)\n",
        "    df[\"dir_episodesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(episodes,))\n",
        "\n",
        "    movies = df[df[\"titleType\"] == \"movie\"].groupby(\"directors\").count()[\"titleType\"].to_dict()\n",
        "    movies = split_and_sum(movies)\n",
        "    df[\"dir_moviesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "    others = df[df[\"titleType\"] != \"movie\"].groupby(\"directors\").count()[\"titleType\"].to_dict()\n",
        "    others = split_and_sum(others)\n",
        "    df[\"dir_othersOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "del seasons,episodes,movies,others,df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in df_list:\n",
        "    df[\"writers_qty\"] = pd.Series(df[\"writers\"]).str.split(\",\").apply(len)\n",
        "\n",
        "    writers = df.groupby(\"writers\").count()[\"Unnamed: 0\"].to_dict()\n",
        "    writers = split_and_sum(writers)\n",
        "    df[\"writers_exp\"] = df[\"writers\"].apply(sum_into_column,args=(writers,))\n",
        "\n",
        "    df[\"writer_minExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers,0,))\n",
        "\n",
        "    df[\"writer_maxExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers,1,))\n",
        "\n",
        "\n",
        "    seasons = df.groupby(\"writers\").count()[\"seasonNumber\"].to_dict()\n",
        "    seasons = split_and_sum(seasons)\n",
        "    df[\"writer_seasonsOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(seasons,))\n",
        "\n",
        "    episodes = df.groupby(\"writers\").count()[\"episodeNumber\"].to_dict()\n",
        "    episodes = split_and_sum(episodes)\n",
        "    df[\"writer_episodesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(episodes,))\n",
        "\n",
        "    movies = df[df[\"titleType\"] == \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "    movies = split_and_sum(movies)\n",
        "    df[\"writer_moviesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "    others = df[df[\"titleType\"] != \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "    others = split_and_sum(others)\n",
        "    df[\"writer_othersOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "\n",
        "del seasons,episodes,movies,others,df,writers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ianda\\AppData\\Local\\Temp\\ipykernel_31308\\2738369730.py:40: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  dir_votes = df.groupby(\"directors\").sum()[\"numVotes\"].to_dict()\n",
            "C:\\Users\\ianda\\AppData\\Local\\Temp\\ipykernel_31308\\2738369730.py:40: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  dir_votes = df.groupby(\"directors\").sum()[\"numVotes\"].to_dict()\n"
          ]
        }
      ],
      "source": [
        "def parse_json(x):\n",
        "    x = x.split(\":\")\n",
        "    x = x[1:]\n",
        "    for i in range(len(x)):\n",
        "        x[i] = x[i].split(\"}\")[0]\n",
        "        x[i] = x[i].split(\",\")[0]\n",
        "    \n",
        "    #split the list into pairs of two\n",
        "    x = [x[i:i+2] for i in range(0,len(x),2)]\n",
        "    # grab the first element of the pair\n",
        "    x = [i[0] for i in x]\n",
        "    #remove the quotes\n",
        "    x = [i.replace(\"'\",'') for i in x]\n",
        "    #remove the spaces\n",
        "    x = [i.strip() for i in x]\n",
        "\n",
        "    return \",\".join(x)\n",
        "for df in df_list:\n",
        "    #turn production company into a list\n",
        "    #fill nans with empty list\n",
        "    df[\"production_countries\"] = df[\"production_countries\"].fillna(\"[]\")\n",
        "    #turn str list into list\n",
        "    df[\"production_countries\"] = df[\"production_countries\"].apply(parse_json)\n",
        "    experience = split_and_sum(df.groupby(\"production_countries\").count()[\"Unnamed: 0\"].to_dict())\n",
        "    experience['']=0\n",
        "    df[\"production_countries_experience\"] = df[\"production_countries\"].apply(sum_into_column,args=(experience,))\n",
        "\n",
        "    df['production_countries'] = df['production_countries'].apply(lambda x: len(x.split(',')))\n",
        "\n",
        "    #turn production company into a list\n",
        "    #fill nans with empty list\n",
        "    df[\"production_companies\"] = df[\"production_companies\"].fillna(\"[]\")\n",
        "    #turn str list into list\n",
        "    df[\"production_companies\"] = df[\"production_companies\"].apply(parse_json)\n",
        "    experience = split_and_sum(df.groupby(\"production_companies\").count()[\"Unnamed: 0\"].to_dict())\n",
        "    experience['']=0\n",
        "    df[\"production_companies_experience\"] = df[\"production_companies\"].apply(sum_into_column,args=(experience,))\n",
        "\n",
        "    df['production_companies'] = df['production_companies'].apply(lambda x: len(x.split(',')))\n",
        "    dir_votes = df.groupby(\"directors\").sum()[\"numVotes\"].to_dict()\n",
        "    dir_votes = split_and_sum(dir_votes)\n",
        "    df[\"dir_votes\"] = df[\"directors\"].apply(sum_into_column,args=(dir_votes,))\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# turn video colunm into 1 or 0\n",
        "# video column might have False, True or NaN values\n",
        "for df in df_list:\n",
        "    df[\"video\"] = df[\"video\"].fillna(False)\n",
        "    df[\"video\"] = df[\"video\"].astype(int)\n",
        "    df[\"tagline\"] = df[\"tagline\"].fillna(\"\")\n",
        "    df[\"tagline\"] = df[\"tagline\"].apply(len)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "y=df_train.averageRating\n",
        "vars=['startYear', 'runtimeMinutes',\"numVotes\",\"writers_exp\",\n",
        "      \"directors_exp\",\"endYear\",\"isAdult\",\"seasonNumber\",\n",
        "      \"episodeNumber\",\"ordering\",\"isOriginalTitle\",\n",
        "      \"popularity\",\"budget\",\"dir_seasonsOfExperience\",\n",
        "      \"dir_episodesOfExperience\",\"dir_othersOfExperience\",\"dir_moviesOfExperience\",\n",
        "      \"writer_seasonsOfExperience\",\"writer_episodesOfExperience\",\"writer_othersOfExperience\",\n",
        "      \"writer_moviesOfExperience\",\"video\",\"tagline\",\"production_countries\",\"production_countries_experience\",\n",
        "      \"dir_votes\",'production_companies', 'production_companies_experience',\"writers_qty\",\"dir_qty\",\"dir_minExperience\",\"dir_maxExperience\",\n",
        "      \"writer_minExperience\",\"writer_maxExperience\"]\n",
        "X_pred=df_val[vars]\n",
        "vars.append(\"averageRating\")\n",
        "X=df_train[vars]\n",
        "#X_test=df_test[vars]\n",
        "\n",
        "for db in [[X,df_train],[X_pred,df_val]]:\n",
        "      db[0] = pd.concat([db[0], pd.get_dummies(db[1]['language'], prefix='language')], axis=1)\n",
        "      db[0] = pd.concat([db[0], pd.get_dummies(db[1]['status'], prefix='status')], axis=1)\n",
        "\n",
        "del db\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "K2cfK0WTjylW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Done!\n",
            "1 Done!\n"
          ]
        }
      ],
      "source": [
        "for i,df in enumerate(df_list):\n",
        "    encoder = OneHotEncoder()\n",
        "    title = encoder.fit_transform(df[['titleType']])\n",
        "    title_df = pd.DataFrame(title.toarray(), columns=encoder.get_feature_names_out(['titleType']))\n",
        "    #split by genres\n",
        "    genres = df.genres_x.str.get_dummies(sep=',')\n",
        "    genres = genres.reindex(sorted(genres.columns), axis=1)\n",
        "\n",
        "    title_df = pd.concat([title_df, genres], axis=1)\n",
        "    if i==0:\n",
        "        X = pd.concat([X, title_df], axis=1)\n",
        "    elif i==1:\n",
        "        X_pred = pd.concat([X_pred, title_df], axis=1)\n",
        "    print(i,\"Done!\")\n",
        "    \n",
        "\n",
        "\n",
        "del title_df, genres, title, encoder, df,i\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop duplicate columns\n",
        "X = X.loc[:, ~X.columns.duplicated()]\n",
        "X_pred = X_pred.loc[:, ~X_pred.columns.duplicated()]\n",
        "\n",
        "\n",
        "# Add missing columns to X_pred and X_test\n",
        "missing_cols = set(X.columns) - set(X_pred.columns)\n",
        "X_pred = X_pred.reindex(columns=X_pred.columns.tolist() + list(missing_cols))\n",
        "\n",
        "\n",
        "# Add missing columns to X\n",
        "missing_cols = set(X_pred.columns) - set(X.columns)\n",
        "X = X.reindex(columns=X.columns.tolist() + list(missing_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_pred = X_pred.sort_index(axis=1)\n",
        "X = X.sort_index(axis=1)\n",
        "\n",
        "\n",
        "#Drop averageRating from X_pred\n",
        "X_pred = X_pred.drop(columns=[\"averageRating\"])\n",
        "\n",
        "X.to_csv('dataset/train.csv', index=False)\n",
        "X_pred.to_csv('dataset/val.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWrEHZs9zDfmtIg+jWBoNC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
