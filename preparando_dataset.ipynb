{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/AnalisisPredictivo/blob/master/Kaggle/2023Q2/Un_primer_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uK-5cdUyNiQ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from preparando_datos import sum_into_column,split_and_sum\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DP11tcaGOEfg"
      },
      "outputs": [],
      "source": [
        "df_val=pd.read_csv('dataset/testear.csv')\n",
        "df_train=pd.read_csv('dataset/origen.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasons worked\n",
        "for df in [df_val,df_train]:\n",
        "    seasons = df.groupby(\"directors\").count()[\"seasonNumber\"].to_dict()\n",
        "    seasons = split_and_sum(seasons)\n",
        "    df[\"seasonsOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(seasons,))\n",
        "\n",
        "# episodes worked\n",
        "for df in [df_val,df_train]:\n",
        "    episodes = df.groupby(\"directors\").count()[\"episodeNumber\"].to_dict()\n",
        "    episodes = split_and_sum(episodes)\n",
        "    df[\"episodesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(episodes,))\n",
        "    \n",
        "# movies worked\n",
        "for df in [df_val,df_train]:\n",
        "    movies = df[df[\"titleType\"] == \"movie\"].groupby(\"directors\").count()[\"titleType\"].to_dict()\n",
        "    movies = split_and_sum(movies)\n",
        "    df[\"moviesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "# other xp than movies\n",
        "for df in [df_val,df_train]:\n",
        "    others = df[df[\"titleType\"] != \"movie\"].groupby(\"directors\").count()[\"titleType\"].to_dict()\n",
        "    others = split_and_sum(others)\n",
        "    df[\"othersOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "del seasons,episodes,movies,others,df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 9.38 GiB for an array with shape (977541, 1288) and data type object",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Ian\\Documents\\Github\\preditiva\\preparando_dataset.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/Documents/Github/preditiva/preparando_dataset.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m [df_train, df_val]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/Documents/Github/preditiva/preparando_dataset.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     writers \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mwriters\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ian/Documents/Github/preditiva/preparando_dataset.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     writers \u001b[39m=\u001b[39m writers\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m, expand\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/Documents/Github/preditiva/preparando_dataset.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     writer_counts \u001b[39m=\u001b[39m writers\u001b[39m.\u001b[39mstack()\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mto_dict()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ian/Documents/Github/preditiva/preparando_dataset.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     writer_counts[\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Ian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:129\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Ian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:895\u001b[0m, in \u001b[0;36mStringMethods.split\u001b[1;34m(self, pat, n, expand, regex)\u001b[0m\n\u001b[0;32m    893\u001b[0m     regex \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    894\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39marray\u001b[39m.\u001b[39m_str_split(pat, n, expand, regex)\n\u001b[1;32m--> 895\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrap_result(result, returns_string\u001b[39m=\u001b[39;49mexpand, expand\u001b[39m=\u001b[39;49mexpand)\n",
            "File \u001b[1;32mc:\\Users\\Ian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:383\u001b[0m, in \u001b[0;36mStringMethods._wrap_result\u001b[1;34m(self, result, name, expand, fill_value, returns_string, returns_bool)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m expand:\n\u001b[0;32m    382\u001b[0m     cons \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_orig\u001b[39m.\u001b[39m_constructor_expanddim\n\u001b[1;32m--> 383\u001b[0m     result \u001b[39m=\u001b[39m cons(result, columns\u001b[39m=\u001b[39;49mname, index\u001b[39m=\u001b[39;49mindex, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[39m# Must be a Series\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     cons \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_orig\u001b[39m.\u001b[39m_constructor\n",
            "File \u001b[1;32mc:\\Users\\Ian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 782\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    783\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    784\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    785\u001b[0m         data,\n\u001b[0;32m    786\u001b[0m         columns,\n\u001b[0;32m    787\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    788\u001b[0m         dtype,\n\u001b[0;32m    789\u001b[0m     )\n\u001b[0;32m    790\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    791\u001b[0m         arrays,\n\u001b[0;32m    792\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    795\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Ian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[1;32m--> 498\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    499\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    501\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Ian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:830\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[39mreturn\u001b[39;00m arrays, columns\n\u001b[0;32m    829\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m--> 830\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m    831\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], abc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m    832\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_dict_to_arrays(data, columns)\n",
            "File \u001b[1;32mc:\\Users\\Ian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:851\u001b[0m, in \u001b[0;36m_list_to_arrays\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    848\u001b[0m     content \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mto_object_array_tuples(data)\n\u001b[0;32m    849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[39m# list of lists\u001b[39;00m\n\u001b[1;32m--> 851\u001b[0m     content \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mto_object_array(data)\n\u001b[0;32m    852\u001b[0m \u001b[39mreturn\u001b[39;00m content\n",
            "File \u001b[1;32mc:\\Users\\Ian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2883\u001b[0m, in \u001b[0;36mpandas._libs.lib.to_object_array\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.38 GiB for an array with shape (977541, 1288) and data type object"
          ]
        }
      ],
      "source": [
        "def give_authors_experience(writer):\n",
        "    authors = []\n",
        "    if type(writer) != str:\n",
        "        return 0\n",
        "    \n",
        "    for i,author in enumerate(writer.split(',')):\n",
        "        authors.append(writer_counts[author])\n",
        "    \n",
        "    return sum(authors)\n",
        "\n",
        "for df in [df_train, df_val]:\n",
        "\n",
        "    writers = df['writers']\n",
        "    writers = writers.str.split(',', expand=True)\n",
        "    writer_counts = writers.stack().value_counts().to_dict()\n",
        "    writer_counts['0'] = 0\n",
        "\n",
        "    df['writers_exp'] = df['writers'].apply(give_authors_experience)\n",
        "\n",
        "\n",
        "del writers, writer_counts,df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def give_directors_experience(director):\n",
        "    directors = []\n",
        "    if type(director) != str:\n",
        "        return directors\n",
        "    \n",
        "    for i,author in enumerate(director.split(',')):\n",
        "        directors.append(directors_counts[author])\n",
        "    \n",
        "    return sum(directors)\n",
        "\n",
        "for df in [df_train, df_val]:\n",
        "        \n",
        "    directors = df['directors']\n",
        "    directors = directors.str.split(',', expand=True)\n",
        "    directors_counts = directors.stack().value_counts()\n",
        "    directors_counts['0'] = 0\n",
        "\n",
        "\n",
        "    #apply the function to the writers column, send also the ratings column to the function\n",
        "    df['directors_exp'] = df['directors'].apply(give_directors_experience)\n",
        "\n",
        "\n",
        "\n",
        "del directors, directors_counts, df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set language to 0 if it is nan\n",
        "\n",
        "df_train['language'] = df_train['language'].fillna(0)\n",
        "df_val['language'] = df_val['language'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y=df_train.averageRating\n",
        "vars=['startYear', 'runtimeMinutes',\"numVotes\",\"writers_exp\",\n",
        "      \"directors_exp\",\"endYear\",\"isAdult\",\"seasonNumber\",\n",
        "      \"episodeNumber\",\"ordering\",\"isOriginalTitle\",\"runtime\",\n",
        "      \"revenue\",\"popularity\",\"budget\",\"seasonsOfExperience\",\n",
        "      \"episodesOfExperience\",\"othersOfExperience\",\"moviesOfExperience\"]\n",
        "X=df_train[vars]\n",
        "X = pd.concat([X, pd.get_dummies(df_train['language'], prefix='language')], axis=1)\n",
        "X_pred=df_val[vars]\n",
        "X_pred = pd.concat([X_pred, pd.get_dummies(df_val['language'], prefix='language')], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2cfK0WTjylW"
      },
      "outputs": [],
      "source": [
        "for i,df in enumerate([df_train, df_val]):\n",
        "    encoder = OneHotEncoder()\n",
        "    title = encoder.fit_transform(df[['titleType']])\n",
        "    title_df = pd.DataFrame(title.toarray(), columns=encoder.get_feature_names_out(['titleType']))\n",
        "    #split by genres\n",
        "    genres = df.genres_x.str.get_dummies(sep=',')\n",
        "    genres = genres.reindex(sorted(genres.columns), axis=1)\n",
        "\n",
        "\n",
        "    title_df = pd.concat([title_df, genres], axis=1)\n",
        "    if not i:\n",
        "        X = pd.concat([X, title_df], axis=1)\n",
        "    else:\n",
        "        X_pred = pd.concat([X_pred, title_df], axis=1)\n",
        "\n",
        "\n",
        "for col in X.columns:\n",
        "    if col not in X_pred.columns:\n",
        "        X_pred[col] = 0\n",
        "\n",
        "X_pred = X_pred.sort_index(axis=1)\n",
        "X = X.sort_index(axis=1)\n",
        "del title_df, genres, title, encoder, df\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#drop X column named language_0\n",
        "X = X.drop(columns=['language_0'])\n",
        "X_pred = X_pred.drop(columns=['language_0'])\n",
        "print(X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.to_csv('dataset/train.csv', index=False)\n",
        "X_pred.to_csv('dataset/val.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWrEHZs9zDfmtIg+jWBoNC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
