{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/AnalisisPredictivo/blob/master/Kaggle/2023Q2/Un_primer_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK-5cdUyNiQ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import json,re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from preparando_datos import sum_into_column,split_and_sum,get_min_max\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP11tcaGOEfg"
      },
      "outputs": [],
      "source": [
        "df_val=pd.read_csv('dataset/testear.csv')\n",
        "df_train=pd.read_csv('dataset/origen.csv')\n",
        "#split the train dataset into train and test\n",
        "#df_train, df_test = train_test_split(df_train, test_size=0.1, random_state=421)\n",
        "\n",
        "df_list = [df_train,df_val]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df in df_list:\n",
        "    # if isAdult is larger than 1, then set it to 1, if smaller that 0, then set it to 0\n",
        "    df['isAdult'] = df['isAdult'].apply(lambda x: 1 if x > 1 else x)\n",
        "    df['seasonNumber'] = df['seasonNumber'].fillna(0)\n",
        "    df['episodeNumber'] = df['episodeNumber'].fillna(1)\n",
        "    df['ordering'] = df['ordering'].fillna(0)\n",
        "    df['language'] = df['language'].fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ADAPTADO A PIPELINE\n",
        "# Completando los 0 con los promedios tomando en cuenta si son series, peliculas o episodios\n",
        "for df in df_list:\n",
        "    df['runtimeMinutes'] = df['runtimeMinutes'].replace(0, np.nan)\n",
        "    df['runtimeMinutes'] = df.groupby('titleType')['runtimeMinutes'].apply(lambda x: x.interpolate(method='linear'))\n",
        "\n",
        "    #Lo mismo pero para el budget\n",
        "    df['budget'] = df['budget'].replace(0, np.nan)\n",
        "    df['budget'] = df.groupby('titleType')['budget'].apply(lambda x: x.interpolate(method='linear'))\n",
        "    \n",
        "    # Si endYear es 0, entonces se le asigna el valor de startYear\n",
        "    df['endYear'] = df.apply(lambda x: x['startYear'] if x['endYear'] == 0 else x['endYear'], axis=1)\n",
        "\n",
        "    # Lo mismo pero para revenue\n",
        "    df['revenue'] = df['revenue'].replace(0, np.nan)\n",
        "    df['revenue'] = df.groupby('titleType')['revenue'].apply(lambda x: x.interpolate(method='linear'))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ADAPTADO A PIPELINE\n",
        "def get_exp_dict(df:pd.DataFrame,group:str,categories:str):\n",
        "    categorias = df[categories].unique().tolist()\n",
        "    categorias = [x.split(',') if type(x) == str else [] for x in categorias]\n",
        "    categorias = [item for sublist in categorias for item in sublist]\n",
        "    categorias = list(set(categorias))\n",
        "\n",
        "    grupo = df.groupby(group)[categories].apply(list).to_dict()\n",
        "    if '0' in grupo:\n",
        "        del grupo['0']\n",
        "    \n",
        "    dict_limpio = dict()\n",
        "    for director in grupo.keys():\n",
        "        shows = grupo[director]\n",
        "        \n",
        "        for dir in director.split(','):\n",
        "            if dir in dict_limpio:\n",
        "                dict_limpio[dir] += shows\n",
        "            else:\n",
        "                dict_limpio[dir] = shows\n",
        "    for director in dict_limpio.keys():\n",
        "        #split all the genres into a list\n",
        "        dict_limpio[director] = [x.split(',') if type(x) == str else [] for x in dict_limpio[director]]\n",
        "        #flatten the list\n",
        "        dict_limpio[director] = [item for sublist in dict_limpio[director] for item in sublist]\n",
        "        #turn the list into a dict and count the number of times each genre appears\n",
        "        dict_limpio[director] = dict((x,dict_limpio[director].count(x)) for x in set(dict_limpio[director]))\n",
        "        # if not all genres are present, add the missing ones and set the count to 0\n",
        "        for cat in categorias:\n",
        "            if cat not in dict_limpio[director]:\n",
        "                dict_limpio[director][cat] = 0\n",
        "    return dict_limpio,categorias\n",
        "\n",
        "\n",
        "def set_exp_by_cat(df:pd.DataFrame,group:str,dict_limpio:dict,categorias:list):\n",
        "    for cat in categorias:\n",
        "        df[f'{group}_exp_{cat}']=df['directors'].apply(sum_into_column,args=(dict_limpio,cat,))\n",
        "    print('Done')\n",
        "\n",
        "dirs_exp_genres,genres = get_exp_dict(df_train,'directors','genres_x')\n",
        "\"\"\" writers_exp_genres,genres = get_exp_dict(df_train,'writers','genres_x')\n",
        "dirs_exp_titleType,titleType = get_exp_dict(df_train,'directors','titleType')\n",
        "writers_exp_titleType,titleType = get_exp_dict(df_train,'writers','titleType') \"\"\"\n",
        "\n",
        "for df in df_list:\n",
        "    set_exp_by_cat(df,'genres_x',dirs_exp_genres,genres)\n",
        "    \"\"\" set_exp_by_cat(df,'genres_x',writers_exp_genres,genres)\n",
        "    set_exp_by_cat(df,'titleType',dirs_exp_titleType,titleType)\n",
        "    set_exp_by_cat(df,'titleType',writers_exp_titleType,titleType) \"\"\"\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasons worked\n",
        "\n",
        "writers = df_train.groupby(\"writers\").count()[\"Unnamed: 0\"].to_dict()\n",
        "writers = split_and_sum(writers)\n",
        "seasons = df_train.groupby(\"writers\").count()[\"seasonNumber\"].to_dict()\n",
        "seasons = split_and_sum(seasons)\n",
        "episodes = df_train.groupby(\"writers\").count()[\"episodeNumber\"].to_dict()\n",
        "episodes = split_and_sum(episodes)\n",
        "movies = df_train[df_train[\"titleType\"] == \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "movies = split_and_sum(movies)\n",
        "others = df_train[df_train[\"titleType\"] != \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "others = split_and_sum(others)\n",
        "\n",
        "for df in df_list:\n",
        "    \n",
        "    df[\"dir_qty\"] = pd.Series(df[\"directors\"]).str.split(\",\").apply(len)\n",
        "\n",
        "\n",
        "    df[\"directors_exp\"] = df[\"directors\"].apply(sum_into_column,args=(writers,))\n",
        "\n",
        "    df[\"dir_minExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,0,))\n",
        "\n",
        "    df[\"dir_maxExperience\"] = df[\"directors\"].apply(get_min_max,args=(writers,1,))\n",
        "\n",
        "    df[\"dir_seasonsOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(seasons,))\n",
        "\n",
        "\n",
        "    df[\"dir_episodesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(episodes,))\n",
        "\n",
        "\n",
        "    df[\"dir_moviesOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "    df[\"dir_othersOfExperience\"] = df[\"directors\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "del seasons,episodes,movies,others,df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "writers_exp = df_train.groupby(\"writers\").count()[\"Unnamed: 0\"].to_dict()\n",
        "writers_exp = split_and_sum(writers_exp)\n",
        "seasons = df_train.groupby(\"writers\").count()[\"seasonNumber\"].to_dict()\n",
        "seasons = split_and_sum(seasons)\n",
        "episodes = df_train.groupby(\"writers\").count()[\"episodeNumber\"].to_dict()\n",
        "episodes = split_and_sum(episodes)\n",
        "movies = df_train[df_train[\"titleType\"] == \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "movies = split_and_sum(movies)\n",
        "others = df_train[df_train[\"titleType\"] != \"movie\"].groupby(\"writers\").count()[\"titleType\"].to_dict()\n",
        "others = split_and_sum(others)\n",
        "\n",
        "\n",
        "for df in df_list:\n",
        "    df[\"writers_qty\"] = pd.Series(df[\"writers\"]).str.split(\",\").apply(len)\n",
        "\n",
        "    df[\"writers_exp\"] = df[\"writers\"].apply(sum_into_column,args=(writers_exp,))\n",
        "\n",
        "    df[\"writer_minExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers_exp,0,))\n",
        "\n",
        "    df[\"writer_maxExperience\"] = df[\"writers\"].apply(get_min_max,args=(writers_exp,1,))\n",
        "\n",
        "    df[\"writer_seasonsOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(seasons,))\n",
        "    \n",
        "    df[\"writer_episodesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(episodes,))\n",
        "\n",
        "    df[\"writer_moviesOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(movies,))\n",
        "\n",
        "    df[\"writer_othersOfExperience\"] = df[\"writers\"].apply(sum_into_column,args=(others,))\n",
        "\n",
        "\n",
        "del seasons,episodes,movies,others,df,writers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_json(x):\n",
        "    x = x.split(\":\")\n",
        "    x = x[1:]\n",
        "    for i in range(len(x)):\n",
        "        x[i] = x[i].split(\"}\")[0]\n",
        "        x[i] = x[i].split(\",\")[0]\n",
        "    \n",
        "    #split the list into pairs of two\n",
        "    x = [x[i:i+2] for i in range(0,len(x),2)]\n",
        "    # grab the first element of the pair\n",
        "    x = [i[0] for i in x]\n",
        "    #remove the quotes\n",
        "    x = [i.replace(\"'\",'') for i in x]\n",
        "    #remove the spaces\n",
        "    x = [i.strip() for i in x]\n",
        "\n",
        "    return \",\".join(x)\n",
        "\n",
        "for df in df_list:\n",
        "    df[\"production_countries\"] = df[\"production_countries\"].fillna(\"[]\")\n",
        "    #turn str list into list\n",
        "    df[\"production_countries\"] = df[\"production_countries\"].apply(parse_json)\n",
        "\n",
        "    df[\"production_companies\"] = df[\"production_companies\"].fillna(\"[]\")\n",
        "    #turn str list into list\n",
        "    df[\"production_companies\"] = df[\"production_companies\"].apply(parse_json)\n",
        "\n",
        "experience = df_train.groupby(\"genres_x\").count()[\"Unnamed: 0\"].to_dict()\n",
        "experience['']=0\n",
        "\n",
        "companies_experience = split_and_sum(df.groupby(\"production_companies\").count()[\"Unnamed: 0\"].to_dict())\n",
        "companies_experience['']=0\n",
        "\n",
        "dir_votes = df_train.groupby(\"directors\").sum()[\"numVotes\"].to_dict()\n",
        "dir_votes = split_and_sum(dir_votes)\n",
        "\n",
        "for df in df_list:\n",
        "\n",
        "    df[\"production_countries_experience\"] = df[\"production_countries\"].apply(sum_into_column,args=(experience,))\n",
        "\n",
        "    df['production_countries'] = df['production_countries'].apply(lambda x: len(x.split(',')))\n",
        "\n",
        "    #turn production company into a list\n",
        "    #fill nans with empty list\n",
        "\n",
        "\n",
        "    df[\"production_companies_experience\"] = df[\"production_companies\"].apply(sum_into_column,args=(companies_experience,))\n",
        "\n",
        "    df['production_companies'] = df['production_companies'].apply(lambda x: len(x.split(',')))\n",
        "    \n",
        "    df[\"dir_votes\"] = df[\"directors\"].apply(sum_into_column,args=(dir_votes,))\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# turn video colunm into 1 or 0\n",
        "# video column might have False, True or NaN values\n",
        "for df in df_list:\n",
        "    df[\"video\"] = df[\"video\"].fillna(False)\n",
        "    df[\"video\"] = df[\"video\"].astype(int)\n",
        "    df[\"tagline\"] = df[\"tagline\"].fillna(\"\")\n",
        "    df[\"tagline\"] = df[\"tagline\"].apply(len)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y=df_train.averageRating\n",
        "vars=['Unnamed: 0',  'titleType',\n",
        "       'genres_x', 'directors',\n",
        "       'writers','language',\n",
        "       'attributes', 'genres_y',\n",
        "        'production_companies',\n",
        "       'production_countries', 'adult',\n",
        "       'original_language', 'runtime', 'status']\n",
        "\n",
        "\n",
        "         # 'revenue' Evaluar si sirve o no\n",
        "       \n",
        "       \n",
        "X_pred = df_val.drop(columns= vars)\n",
        "X = df_train.drop(columns= vars)\n",
        "#X_test=df_test[vars]\n",
        "\n",
        "for db in [[X,df_train],[X_pred,df_val]]:\n",
        "      db[0] = pd.concat([db[0], pd.get_dummies(db[1]['language'], prefix='language')], axis=1)\n",
        "      db[0] = pd.concat([db[0], pd.get_dummies(db[1]['status'], prefix='status')], axis=1)\n",
        "\n",
        "del db\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2cfK0WTjylW"
      },
      "outputs": [],
      "source": [
        "for i,df in enumerate(df_list):\n",
        "    encoder = OneHotEncoder()\n",
        "    title = encoder.fit_transform(df[['titleType']])\n",
        "    title_df = pd.DataFrame(title.toarray(), columns=encoder.get_feature_names_out(['titleType']))\n",
        "    #split by genres\n",
        "    genres = df.genres_x.str.get_dummies(sep=',')\n",
        "    genres = genres.reindex(sorted(genres.columns), axis=1)\n",
        "\n",
        "    title_df = pd.concat([title_df, genres], axis=1)\n",
        "    if i==0:\n",
        "        X = pd.concat([X, title_df], axis=1)\n",
        "    elif i==1:\n",
        "        X_pred = pd.concat([X_pred, title_df], axis=1)\n",
        "    print(i,\"Done!\")\n",
        "    \n",
        "\n",
        "\n",
        "del title_df, genres, title, encoder, df,i\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop duplicate columns\n",
        "X = X.loc[:, ~X.columns.duplicated()]\n",
        "X_pred = X_pred.loc[:, ~X_pred.columns.duplicated()]\n",
        "\n",
        "\n",
        "# Add missing columns to X_pred and X_test\n",
        "missing_cols = set(X.columns) - set(X_pred.columns)\n",
        "X_pred = X_pred.reindex(columns=X_pred.columns.tolist() + list(missing_cols))\n",
        "\n",
        "\n",
        "# Add missing columns to X\n",
        "missing_cols = set(X_pred.columns) - set(X.columns)\n",
        "X = X.reindex(columns=X.columns.tolist() + list(missing_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_pred = X_pred.sort_index(axis=1)\n",
        "X = X.sort_index(axis=1)\n",
        "\n",
        "\n",
        "#Drop averageRating from X_pred\n",
        "X_pred = X_pred.drop(columns=[\"averageRating\"])\n",
        "\n",
        "X.to_csv('dataset/train.csv', index=False)\n",
        "X_pred.to_csv('dataset/val.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWrEHZs9zDfmtIg+jWBoNC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
